{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60f3d43",
   "metadata": {},
   "source": [
    "# ğŸ”¥ PyTorch: Tensors & Autograd (Silnik Deep Learningu)\n",
    "\n",
    "Wchodzimy w Å›wiat \"Prawdziwego AI\".\n",
    "WiÄ™kszoÅ›Ä‡ modeli, o ktÃ³rych sÅ‚yszysz (ChatGPT, Stable Diffusion), jest napisana w **PyTorch**.\n",
    "\n",
    "Zrozumiemy dziÅ› dwa pojÄ™cia:\n",
    "\n",
    "1.  **Tensor:**\n",
    "    *   W NumPy mamy `np.array`.\n",
    "    *   W PyTorch mamy `torch.Tensor`.\n",
    "    *   RÃ³Å¼nica? Tensor moÅ¼na wrzuciÄ‡ na **GPU** (kartÄ™ graficznÄ…), co przyspiesza obliczenia 100x.\n",
    "\n",
    "2.  **Autograd (Automatic Differentiation):**\n",
    "    *   W Deep Learningu musimy liczyÄ‡ spadki (gradienty), Å¼eby uczyÄ‡ sieÄ‡.\n",
    "    *   Liczenie tego rÄ™cznie dla miliona wag jest niemoÅ¼liwe.\n",
    "    *   PyTorch \"Å›ledzi\" kaÅ¼de dziaÅ‚anie matematyczne, jakie wykonujesz, i potrafi \"odwinÄ…Ä‡ je do tyÅ‚u\", Å¼eby policzyÄ‡ bÅ‚Ä™dy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02dddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.2 environment at: venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 4m 08s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wersja PyTorch: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "# Instalacja (w Colab jest domyÅ›lnie, ale na lokalnym PC trzeba zainstalowaÄ‡)\n",
    "!uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Wersja PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a953120",
   "metadata": {},
   "source": [
    "## Krok 1: Tensor vs NumPy\n",
    "\n",
    "Zobaczysz, Å¼e skÅ‚adnia jest prawie identyczna. JeÅ›li znasz NumPy, znasz PyTorch.\n",
    "Jedyna rÃ³Å¼nica to \"typ\" obiektu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411f72d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "Tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "------------------------------\n",
      "Operacje matematyczne sÄ… takie same:\n",
      "MnoÅ¼enie (NumPy): \n",
      "[[2 4]\n",
      " [6 8]]\n",
      "MnoÅ¼enie (Torch): \n",
      "tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Lista Pythonowa\n",
    "lista = [[1, 2], [3, 4]]\n",
    "\n",
    "# 2. NumPy Array\n",
    "np_array = np.array(lista)\n",
    "\n",
    "# 3. PyTorch Tensor\n",
    "tensor = torch.tensor(lista)\n",
    "\n",
    "print(f\"NumPy:\\n{np_array}\")\n",
    "print(f\"Tensor:\\n{tensor}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Operacje matematyczne sÄ… takie same:\")\n",
    "print(f\"MnoÅ¼enie (NumPy): \\n{np_array * 2}\")\n",
    "print(f\"MnoÅ¼enie (Torch): \\n{tensor * 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90464e",
   "metadata": {},
   "source": [
    "## Krok 2: Magia GPU (CUDA)\n",
    "\n",
    "To jest powÃ³d, dla ktÃ³rego uÅ¼ywamy PyTorch.\n",
    "ZwykÅ‚a macierz NumPy Å¼yje w RAM-ie i jest liczona przez procesor (CPU).\n",
    "Tensor moÅ¼emy wysÅ‚aÄ‡ na kartÄ™ graficznÄ… (GPU/CUDA).\n",
    "\n",
    "*Uwaga: JeÅ›li uruchamiasz to na zwykÅ‚ym laptopie bez NVIDIA GPU, kod uÅ¼yje CPU, ale skÅ‚adnia `to(device)` jest uniwersalna.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b096ffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Znaleziono GPU NVIDIA (CUDA)!\n",
      "Gdzie Å¼yje nasz tensor? cuda:0\n",
      "Teraz wszystkie obliczenia na 'x' bÄ™dÄ… super-szybkie.\n"
     ]
    }
   ],
   "source": [
    "# Sprawdzamy, czy mamy dostÄ™pnÄ… kartÄ™ graficznÄ…\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"âœ… Znaleziono GPU NVIDIA (CUDA)!\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"âœ… Znaleziono GPU Apple Silicon (M1/M2)!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ Brak GPU. UÅ¼ywamy procesora (CPU).\")\n",
    "\n",
    "# Tworzymy tensor\n",
    "x = torch.tensor([10.0, 20.0])\n",
    "\n",
    "# Przenosimy go na urzÄ…dzenie (to trwa uÅ‚amek sekundy, ale fizycznie kopiuje dane)\n",
    "x = x.to(device)\n",
    "\n",
    "print(f\"Gdzie Å¼yje nasz tensor? {x.device}\")\n",
    "print(\"Teraz wszystkie obliczenia na 'x' bÄ™dÄ… super-szybkie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508df4c",
   "metadata": {},
   "source": [
    "## Krok 3: Autograd (Automatyczne Pochodne)\n",
    "\n",
    "To jest **najwaÅ¼niejsza czÄ™Å›Ä‡**.\n",
    "WyobraÅº sobie prostÄ… funkcjÄ™:\n",
    "$$ y = x^2 + 5 $$\n",
    "\n",
    "Chcemy policzyÄ‡ pochodnÄ… (czyli nachylenie/gradient) w punkcie $x=3$.\n",
    "Z matematyki wiemy, Å¼e:\n",
    "$$ y' = 2x $$\n",
    "WiÄ™c dla $x=3$, wynik powinien wynosiÄ‡ $6$.\n",
    "\n",
    "SprawdÅºmy, czy PyTorch policzy to sam, bez znajomoÅ›ci wzoru na pochodnÄ…."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3d0acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 3.0\n",
      "Y (Wynik funkcji): 14.0\n",
      "------------------------------\n",
      "Matematyka mÃ³wi: pochodna z x^2 w punkcie 3 to 2*3 = 6.\n",
      "PyTorch wyliczyÅ‚: 6.0\n",
      "âœ… Autograd dziaÅ‚a idealnie!\n"
     ]
    }
   ],
   "source": [
    "# 1. Definiujemy X\n",
    "# WAÅ»NE: requires_grad=True mÃ³wi PyTorchowi: \"ÅšledÅº kaÅ¼dÄ… operacjÄ™ na tej zmiennej!\"\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# 2. Definiujemy funkcjÄ™ Y (Symulacja bÅ‚Ä™du sieci)\n",
    "# y = x^2 + 5\n",
    "y = x**2 + 5\n",
    "\n",
    "print(f\"X: {x}\")\n",
    "print(f\"Y (Wynik funkcji): {y}\")\n",
    "\n",
    "# 3. MAGIA: Backward Pass (Wsteczna propagacja)\n",
    "# MÃ³wimy: \"Policz, jak zmiana X wpÅ‚ywa na Y\"\n",
    "y.backward()\n",
    "\n",
    "# 4. Sprawdzamy wynik\n",
    "print(\"-\" * 30)\n",
    "print(f\"Matematyka mÃ³wi: pochodna z x^2 w punkcie 3 to 2*3 = 6.\")\n",
    "print(f\"PyTorch wyliczyÅ‚: {x.grad}\")\n",
    "\n",
    "if x.grad == 6.0:\n",
    "    print(\"âœ… Autograd dziaÅ‚a idealnie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5834356",
   "metadata": {},
   "source": [
    "## ğŸ§  Podsumowanie: Po co nam to?\n",
    "\n",
    "W powyÅ¼szym przykÅ‚adzie `y = x^2 + 5`:\n",
    "*   **x** to Wagi twojej sieci neuronowej (to, co chcemy poprawiÄ‡).\n",
    "*   **y** to BÅ‚Ä…d sieci (Loss) - np. rÃ³Å¼nica miÄ™dzy tym co sieÄ‡ przewidziaÅ‚a, a prawdÄ….\n",
    "\n",
    "Gdy wywoÅ‚ujesz `loss.backward()`, PyTorch automatycznie liczy:\n",
    "*\"Jak bardzo muszÄ™ zmieniÄ‡ wagÄ™ X, Å¼eby zmniejszyÄ‡ bÅ‚Ä…d Y?\"*.\n",
    "\n",
    "**Tu jest haczyk.**\n",
    "W GPT-4 masz bilion wag (parametrÃ³w).\n",
    "RÄ™czne liczenie pochodnych zajÄ™Å‚oby wiecznoÅ›Ä‡.\n",
    "PyTorch robi to automatycznie, budujÄ…c w pamiÄ™ci tzw. **Graf Obliczeniowy**. ZapamiÄ™tuje, Å¼e `y` powstaÅ‚o przez podniesienie `x` do kwadratu, wiÄ™c wie, jak wrÃ³ciÄ‡ po swoich Å›ladach.\n",
    "\n",
    "W nastÄ™pnym notatniku uÅ¼yjemy tego, Å¼eby zbudowaÄ‡ prawdziwÄ… sieÄ‡ w stylu **Object Oriented Programming**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
