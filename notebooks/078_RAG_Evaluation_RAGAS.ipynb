{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/ai-engineering-handbook/blob/main/78_RAG_Evaluation_RAGAS.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859376d",
   "metadata": {},
   "source": [
    "# \u2696\ufe0f RAG Evaluation: S\u0119dzia AI (LLM-as-a-Judge)\n",
    "\n",
    "W klasycznym ML mamy `Accuracy` (czy 0=0?). W generatywnym AI odpowied\u017a jest tekstem. Nie da si\u0119 jej por\u00f3wna\u0107 \"znak po znaku\".\n",
    "\n",
    "**Paradygmat LLM-as-a-Judge:**\n",
    "U\u017cywamy jednego modelu AI (S\u0119dziego), \u017ceby ocenia\u0142 drugi model (Studenta).\n",
    "\n",
    "Zbudujemy system oceny **Faithfulness (Wierno\u015bci)**:\n",
    "1.  **Krok 1:** Wyci\u0105gnij z odpowiedzi Studenta wszystkie twierdzenia (fakty).\n",
    "2.  **Krok 2:** Sprawd\u017a ka\u017cdy fakt w Kontek\u015bcie (\u017ar\u00f3d\u0142ach).\n",
    "3.  **Krok 3:** Je\u015bli fakt nie ma pokrycia w \u017ar\u00f3d\u0142ach -> **Halucynacja**.\n",
    "4.  **Wynik:** Liczba fakt\u00f3w potwierdzonych / Liczba wszystkich fakt\u00f3w.\n",
    "\n",
    "To jest dok\u0142adnie to, co robi biblioteka **RAGAS** pod mask\u0105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a936f343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LOGI Z RAG ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case_A_Good</td>\n",
       "      <td>Jaka jest stolica Francji?</td>\n",
       "      <td>Francja to kraj w Europie. Jej stolic\u0105 jest Pa...</td>\n",
       "      <td>Stolic\u0105 Francji jest Pary\u017c.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case_B_Hallucination</td>\n",
       "      <td>Kto wygra\u0142 mundial w 2022?</td>\n",
       "      <td>Mundial 2022 odby\u0142 si\u0119 w Katarze. Bra\u0142a w nim ...</td>\n",
       "      <td>Mundial w 2022 wygra\u0142a Argentyna.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case_C_Irrelevant</td>\n",
       "      <td>Jak zresetowa\u0107 has\u0142o?</td>\n",
       "      <td>Aby zresetowa\u0107 has\u0142o, kliknij w link w mailu.</td>\n",
       "      <td>Has\u0142a s\u0105 wa\u017cne dla bezpiecze\u0144stwa.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                    question  \\\n",
       "0           Case_A_Good  Jaka jest stolica Francji?   \n",
       "1  Case_B_Hallucination  Kto wygra\u0142 mundial w 2022?   \n",
       "2     Case_C_Irrelevant       Jak zresetowa\u0107 has\u0142o?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Francja to kraj w Europie. Jej stolic\u0105 jest Pa...   \n",
       "1  Mundial 2022 odby\u0142 si\u0119 w Katarze. Bra\u0142a w nim ...   \n",
       "2      Aby zresetowa\u0107 has\u0142o, kliknij w link w mailu.   \n",
       "\n",
       "                               answer  \n",
       "0         Stolic\u0105 Francji jest Pary\u017c.  \n",
       "1   Mundial w 2022 wygra\u0142a Argentyna.  \n",
       "2  Has\u0142a s\u0105 wa\u017cne dla bezpiecze\u0144stwa.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 1. DANE DO OCENY (Symulacja log\u00f3w z Twojego RAG-a)\n",
    "# Mamy 3 przypadki:\n",
    "# A: Idealna odpowied\u017a.\n",
    "# B: Halucynacja (zmy\u015bla fakty spoza kontekstu).\n",
    "# C: Nie na temat (Unikanie odpowiedzi).\n",
    "\n",
    "rag_logs = [\n",
    "    {\n",
    "        \"id\": \"Case_A_Good\",\n",
    "        \"question\": \"Jaka jest stolica Francji?\",\n",
    "        \"context\": \"Francja to kraj w Europie. Jej stolic\u0105 jest Pary\u017c.\",\n",
    "        \"answer\": \"Stolic\u0105 Francji jest Pary\u017c.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"Case_B_Hallucination\",\n",
    "        \"question\": \"Kto wygra\u0142 mundial w 2022?\",\n",
    "        \"context\": \"Mundial 2022 odby\u0142 si\u0119 w Katarze. Bra\u0142a w nim udzia\u0142 Polska.\",\n",
    "        \"answer\": \"Mundial w 2022 wygra\u0142a Argentyna.\" \n",
    "        # To prawda w \u017cyciu, ale FA\u0141SZ w kontek\u015bcie RAG! \n",
    "        # Model u\u017cy\u0142 wiedzy z g\u0142owy, a nie z dokumentu. To b\u0142\u0105d Faithfulness.\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"Case_C_Irrelevant\",\n",
    "        \"question\": \"Jak zresetowa\u0107 has\u0142o?\",\n",
    "        \"context\": \"Aby zresetowa\u0107 has\u0142o, kliknij w link w mailu.\",\n",
    "        \"answer\": \"Has\u0142a s\u0105 wa\u017cne dla bezpiecze\u0144stwa.\"\n",
    "        # Prawda, ale nie odpowiada na pytanie. B\u0142\u0105d Relevance.\n",
    "    }\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(rag_logs)\n",
    "print(\"--- LOGI Z RAG ---\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78844a2",
   "metadata": {},
   "source": [
    "## Budowa S\u0119dziego (The Judge)\n",
    "\n",
    "Nie b\u0119dziemy tu podina\u0107 p\u0142atnego API OpenAI.\n",
    "Zapiszemy **Prompty S\u0119dziowskie**, kt\u00f3re normalnie wys\u0142a\u0142by\u015b do GPT-4.\n",
    "Zasymulujemy dzia\u0142anie S\u0119dziego, \u017ceby\u015b zrozumia\u0142 algorytm oceniania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69e1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\u0119dzia gotowy. Mo\u017cemy generowa\u0107 instrukcje dla GPT-4.\n"
     ]
    }
   ],
   "source": [
    "class RAGEvaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def create_faithfulness_prompt(self, context, answer):\n",
    "        \"\"\"\n",
    "        Prompt sprawdzaj\u0105cy, czy model nie k\u0142amie.\n",
    "        \"\"\"\n",
    "        return f\"\"\"\n",
    "        Jeste\u015b S\u0119dzi\u0105 weryfikuj\u0105cym fakty.\n",
    "        \n",
    "        ZADANIE:\n",
    "        1. Rozbij 'Odpowied\u017a' na list\u0119 pojedynczych twierdze\u0144.\n",
    "        2. Dla ka\u017cdego twierdzenia sprawd\u017a, czy wynika ono logicznie z 'Kontekstu'.\n",
    "        3. Je\u015bli wynika -> TAK. Je\u015bli nie ma go w kontek\u015bcie -> NIE.\n",
    "        \n",
    "        Kontekst: \"{context}\"\n",
    "        Odpowied\u017a: \"{answer}\"\n",
    "        \n",
    "        Format wyj\u015bciowy (JSON):\n",
    "        {{\n",
    "            \"statements\": [\"twierdzenie 1\", \"twierdzenie 2\"],\n",
    "            \"verdict\": [\"TAK\", \"NIE\"],\n",
    "            \"score\": (liczba TAK / wszystkie)\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "    def create_relevance_prompt(self, question, answer):\n",
    "        \"\"\"\n",
    "        Prompt sprawdzaj\u0105cy, czy model odpowiedzia\u0142 na temat.\n",
    "        \"\"\"\n",
    "        return f\"\"\"\n",
    "        Jeste\u015b S\u0119dzi\u0105 oceniaj\u0105cym jako\u015b\u0107 rozmowy.\n",
    "        \n",
    "        ZADANIE:\n",
    "        Oce\u0144, czy 'Odpowied\u017a' jest u\u017cyteczna i bezpo\u015brednio odnosi si\u0119 do 'Pytania'.\n",
    "        Ignoruj poprawno\u015b\u0107 fakt\u00f3w (to sprawdzamy gdzie indziej). Skup si\u0119 na intencji.\n",
    "        \n",
    "        Pytanie: \"{question}\"\n",
    "        Odpowied\u017a: \"{answer}\"\n",
    "        \n",
    "        Wynik: 0 (Kompletnie nie na temat) do 1 (Idealna odpowied\u017a).\n",
    "        \"\"\"\n",
    "\n",
    "evaluator = RAGEvaluator()\n",
    "print(\"S\u0119dzia gotowy. Mo\u017cemy generowa\u0107 instrukcje dla GPT-4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fe7df",
   "metadata": {},
   "source": [
    "## Symulacja Oceny (Case B: Halucynacja)\n",
    "\n",
    "Sp\u00f3jrzmy na przypadek B:\n",
    "*   Context: \"Mundial by\u0142 w Katarze.\"\n",
    "*   Answer: \"Wygra\u0142a Argentyna.\"\n",
    "\n",
    "Dla cz\u0142owieka to prawda.\n",
    "Dla systemu RAG to **B\u0142\u0105d Krytyczny**. Je\u015bli w dokumentach firmowych nie ma info o Argentynie, model nie ma prawa o tym pisa\u0107. To si\u0119 nazywa **Data Leakage from Pre-training**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4908b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANALIZA PRZYPADKU: Case_B_Hallucination ---\n",
      "Pytanie: Kto wygra\u0142 mundial w 2022?\n",
      "Kontekst: Mundial 2022 odby\u0142 si\u0119 w Katarze. Bra\u0142a w nim udzia\u0142 Polska.\n",
      "Odpowied\u017a Modelu: Mundial w 2022 wygra\u0142a Argentyna.\n",
      "\n",
      "--- CO WIDZI S\u0118DZIA (PROMPT) ---\n",
      "\n",
      "        Jeste\u015b S\u0119dzi\u0105 weryfikuj\u0105cym fakty.\n",
      "\n",
      "        ZADANIE:\n",
      "        1. Rozbij 'Odpowied\u017a' na list\u0119 pojedynczych twierdze\u0144.\n",
      "        2. Dla ka\u017cdego twierdzenia sprawd\u017a, czy wynika ono logicznie z 'Kontekstu'.\n",
      "        3. Je\u015bli wynika -> TAK. Je\u015bli nie ma go w kontek\u015bcie -> NIE.\n",
      "\n",
      "        Kontekst: \"Mundial 2022 odby\u0142 si\u0119 w Katarze. Bra\u0142a w nim udzia\u0142 Polska.\"\n",
      "        Odpowied\u017a: \"Mundial w 2022 wygra\u0142a Argentyna.\"\n",
      "\n",
      "        Format wyj\u015bciowy (JSON):\n",
      "        {\n",
      "            \"statements\": [\"twierdzenie 1\", \"twierdzenie 2\"],\n",
      "            \"verdict\": [\"TAK\", \"NIE\"],\n",
      "            \"score\": (liczba TAK / wszystkie)\n",
      "        }\n",
      "        \n",
      "\n",
      "--- SYMULOWANA ODPOWIED\u0179 S\u0118DZIEGO (GPT-4) ---\n",
      "{\n",
      "  \"statements\": [\n",
      "    \"Mundial w 2022 wygra\u0142a Argentyna\"\n",
      "  ],\n",
      "  \"verdict\": [\n",
      "    \"NIE\"\n",
      "  ],\n",
      "  \"reasoning\": \"W podanym kontek\u015bcie nie ma informacji o zwyci\u0119zcy. Jest tylko info o lokalizacji.\",\n",
      "  \"score\": 0.0\n",
      "}\n",
      "------------------------------\n",
      "\ud83d\udea8 FAITHFULNESS FAIL: Model u\u017cy\u0142 wiedzy spoza dokumentu!\n"
     ]
    }
   ],
   "source": [
    "case = rag_logs[1] # Case B\n",
    "\n",
    "print(f\"--- ANALIZA PRZYPADKU: {case['id']} ---\")\n",
    "print(f\"Pytanie: {case['question']}\")\n",
    "print(f\"Kontekst: {case['context']}\")\n",
    "print(f\"Odpowied\u017a Modelu: {case['answer']}\")\n",
    "\n",
    "print(\"\\n--- CO WIDZI S\u0118DZIA (PROMPT) ---\")\n",
    "prompt = evaluator.create_faithfulness_prompt(case['context'], case['answer'])\n",
    "print(prompt)\n",
    "\n",
    "print(\"\\n--- SYMULOWANA ODPOWIED\u0179 S\u0118DZIEGO (GPT-4) ---\")\n",
    "# To jest to, co zwr\u00f3ci\u0142by model:\n",
    "simulated_verdict = {\n",
    "    \"statements\": [\"Mundial w 2022 wygra\u0142a Argentyna\"],\n",
    "    \"verdict\": [\"NIE\"],\n",
    "    \"reasoning\": \"W podanym kontek\u015bcie nie ma informacji o zwyci\u0119zcy. Jest tylko info o lokalizacji.\",\n",
    "    \"score\": 0.0\n",
    "}\n",
    "print(json.dumps(simulated_verdict, indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "if simulated_verdict['score'] < 1.0:\n",
    "    print(\"\ud83d\udea8 FAITHFULNESS FAIL: Model u\u017cy\u0142 wiedzy spoza dokumentu!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82ee12",
   "metadata": {},
   "source": [
    "## Symulacja Oceny (Case C: Relevance)\n",
    "\n",
    "Sp\u00f3jrzmy na przypadek C:\n",
    "*   Pytanie: \"Jak zresetowa\u0107 has\u0142o?\"\n",
    "*   Odpowied\u017a: \"Has\u0142a s\u0105 wa\u017cne.\"\n",
    "\n",
    "Model powiedzia\u0142 prawd\u0119, opar\u0142 si\u0119 na swojej wiedzy og\u00f3lnej, ale... nie pom\u00f3g\u0142 u\u017cytkownikowi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1a061d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ANALIZA PRZYPADKU: Case_C_Irrelevant ---\n",
      "\n",
      "        Jeste\u015b S\u0119dzi\u0105 oceniaj\u0105cym jako\u015b\u0107 rozmowy.\n",
      "\n",
      "        ZADANIE:\n",
      "        Oce\u0144, czy 'Odpowied\u017a' jest u\u017cyteczna i bezpo\u015brednio odnosi si\u0119 do 'Pytania'.\n",
      "        Ignoruj poprawno\u015b\u0107 fakt\u00f3w (to sprawdzamy gdzie indziej). Skup si\u0119 na intencji.\n",
      "\n",
      "        Pytanie: \"Jak zresetowa\u0107 has\u0142o?\"\n",
      "        Odpowied\u017a: \"Has\u0142a s\u0105 wa\u017cne dla bezpiecze\u0144stwa.\"\n",
      "\n",
      "        Wynik: 0 (Kompletnie nie na temat) do 1 (Idealna odpowied\u017a).\n",
      "        \n",
      "\n",
      "--- SYMULOWANA ODPOWIED\u0179 S\u0118DZIEGO ---\n",
      "{\n",
      "  \"score\": 0.2,\n",
      "  \"reasoning\": \"U\u017cytkownik pyta\u0142 o instrukcj\u0119 (JAK), model poda\u0142 opini\u0119/fakt og\u00f3lny. Nie rozwi\u0105zuje problemu.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "case = rag_logs[2] # Case C\n",
    "\n",
    "print(f\"--- ANALIZA PRZYPADKU: {case['id']} ---\")\n",
    "prompt = evaluator.create_relevance_prompt(case['question'], case['answer'])\n",
    "print(prompt)\n",
    "\n",
    "print(\"\\n--- SYMULOWANA ODPOWIED\u0179 S\u0118DZIEGO ---\")\n",
    "simulated_verdict_relevance = {\n",
    "    \"score\": 0.2,\n",
    "    \"reasoning\": \"U\u017cytkownik pyta\u0142 o instrukcj\u0119 (JAK), model poda\u0142 opini\u0119/fakt og\u00f3lny. Nie rozwi\u0105zuje problemu.\"\n",
    "}\n",
    "print(json.dumps(simulated_verdict_relevance, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aad98e",
   "metadata": {},
   "source": [
    "## \ud83e\udde0 Podsumowanie: Trust but Verify\n",
    "\n",
    "W in\u017cynierii LLM nie ufamy modelom na s\u0142owo. Budujemy **Testy Jednostkowe** oparte na innym LLM.\n",
    "\n",
    "**Jak to wdro\u017cy\u0107 w firmie?**\n",
    "1.  Zbierasz 50 par (Pytanie, Idealna Odpowied\u017a) \u2013 tzw. **Golden Dataset**.\n",
    "2.  Zmieniasz kod swojego RAG-a (np. zmieniasz Chunk Size).\n",
    "3.  Puszczasz te 50 pyta\u0144 przez nowy system.\n",
    "4.  U\u017cywasz GPT-4 jako S\u0119dziego do oceny Faithfulness i Relevance.\n",
    "5.  Je\u015bli \u015bredni wynik spad\u0142 \u2013 nie wdra\u017casz zmian.\n",
    "\n",
    "Bez tego kr\u0119cisz si\u0119 w k\u00f3\u0142ko (\"Wydaje mi si\u0119, \u017ce teraz dzia\u0142a lepiej\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-handbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}