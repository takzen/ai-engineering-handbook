{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/ai-engineering-handbook/blob/main/notebooks/032_PyTorch_Tensors_Autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f3d43",
   "metadata": {},
   "source": [
    "# \ud83d\udd25 PyTorch: Tensors & Autograd (Silnik Deep Learningu)\n",
    "\n",
    "Wchodzimy w \u015bwiat \"Prawdziwego AI\".\n",
    "Wi\u0119kszo\u015b\u0107 modeli, o kt\u00f3rych s\u0142yszysz (ChatGPT, Stable Diffusion), jest napisana w **PyTorch**.\n",
    "\n",
    "Zrozumiemy dzi\u015b dwa poj\u0119cia:\n",
    "\n",
    "1.  **Tensor:**\n",
    "    *   W NumPy mamy `np.array`.\n",
    "    *   W PyTorch mamy `torch.Tensor`.\n",
    "    *   R\u00f3\u017cnica? Tensor mo\u017cna wrzuci\u0107 na **GPU** (kart\u0119 graficzn\u0105), co przyspiesza obliczenia 100x.\n",
    "\n",
    "2.  **Autograd (Automatic Differentiation):**\n",
    "    *   W Deep Learningu musimy liczy\u0107 spadki (gradienty), \u017ceby uczy\u0107 sie\u0107.\n",
    "    *   Liczenie tego r\u0119cznie dla miliona wag jest niemo\u017cliwe.\n",
    "    *   PyTorch \"\u015bledzi\" ka\u017cde dzia\u0142anie matematyczne, jakie wykonujesz, i potrafi \"odwin\u0105\u0107 je do ty\u0142u\", \u017ceby policzy\u0107 b\u0142\u0119dy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02dddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.2 environment at: venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 4m 08s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wersja PyTorch: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "# Instalacja (w Colab jest domy\u015blnie, ale na lokalnym PC trzeba zainstalowa\u0107)\n",
    "!uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Wersja PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a953120",
   "metadata": {},
   "source": [
    "## Krok 1: Tensor vs NumPy\n",
    "\n",
    "Zobaczysz, \u017ce sk\u0142adnia jest prawie identyczna. Je\u015bli znasz NumPy, znasz PyTorch.\n",
    "Jedyna r\u00f3\u017cnica to \"typ\" obiektu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411f72d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "Tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "------------------------------\n",
      "Operacje matematyczne s\u0105 takie same:\n",
      "Mno\u017cenie (NumPy): \n",
      "[[2 4]\n",
      " [6 8]]\n",
      "Mno\u017cenie (Torch): \n",
      "tensor([[2, 4],\n",
      "        [6, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Lista Pythonowa\n",
    "lista = [[1, 2], [3, 4]]\n",
    "\n",
    "# 2. NumPy Array\n",
    "np_array = np.array(lista)\n",
    "\n",
    "# 3. PyTorch Tensor\n",
    "tensor = torch.tensor(lista)\n",
    "\n",
    "print(f\"NumPy:\\n{np_array}\")\n",
    "print(f\"Tensor:\\n{tensor}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"Operacje matematyczne s\u0105 takie same:\")\n",
    "print(f\"Mno\u017cenie (NumPy): \\n{np_array * 2}\")\n",
    "print(f\"Mno\u017cenie (Torch): \\n{tensor * 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90464e",
   "metadata": {},
   "source": [
    "## Krok 2: Magia GPU (CUDA)\n",
    "\n",
    "To jest pow\u00f3d, dla kt\u00f3rego u\u017cywamy PyTorch.\n",
    "Zwyk\u0142a macierz NumPy \u017cyje w RAM-ie i jest liczona przez procesor (CPU).\n",
    "Tensor mo\u017cemy wys\u0142a\u0107 na kart\u0119 graficzn\u0105 (GPU/CUDA).\n",
    "\n",
    "*Uwaga: Je\u015bli uruchamiasz to na zwyk\u0142ym laptopie bez NVIDIA GPU, kod u\u017cyje CPU, ale sk\u0142adnia `to(device)` jest uniwersalna.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b096ffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Znaleziono GPU NVIDIA (CUDA)!\n",
      "Gdzie \u017cyje nasz tensor? cuda:0\n",
      "Teraz wszystkie obliczenia na 'x' b\u0119d\u0105 super-szybkie.\n"
     ]
    }
   ],
   "source": [
    "# Sprawdzamy, czy mamy dost\u0119pn\u0105 kart\u0119 graficzn\u0105\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"\u2705 Znaleziono GPU NVIDIA (CUDA)!\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"\u2705 Znaleziono GPU Apple Silicon (M1/M2)!\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"\u26a0\ufe0f Brak GPU. U\u017cywamy procesora (CPU).\")\n",
    "\n",
    "# Tworzymy tensor\n",
    "x = torch.tensor([10.0, 20.0])\n",
    "\n",
    "# Przenosimy go na urz\u0105dzenie (to trwa u\u0142amek sekundy, ale fizycznie kopiuje dane)\n",
    "x = x.to(device)\n",
    "\n",
    "print(f\"Gdzie \u017cyje nasz tensor? {x.device}\")\n",
    "print(\"Teraz wszystkie obliczenia na 'x' b\u0119d\u0105 super-szybkie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508df4c",
   "metadata": {},
   "source": [
    "## Krok 3: Autograd (Automatyczne Pochodne)\n",
    "\n",
    "To jest **najwa\u017cniejsza cz\u0119\u015b\u0107**.\n",
    "Wyobra\u017a sobie prost\u0105 funkcj\u0119:\n",
    "$$ y = x^2 + 5 $$\n",
    "\n",
    "Chcemy policzy\u0107 pochodn\u0105 (czyli nachylenie/gradient) w punkcie $x=3$.\n",
    "Z matematyki wiemy, \u017ce:\n",
    "$$ y' = 2x $$\n",
    "Wi\u0119c dla $x=3$, wynik powinien wynosi\u0107 $6$.\n",
    "\n",
    "Sprawd\u017amy, czy PyTorch policzy to sam, bez znajomo\u015bci wzoru na pochodn\u0105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f3d0acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 3.0\n",
      "Y (Wynik funkcji): 14.0\n",
      "------------------------------\n",
      "Matematyka m\u00f3wi: pochodna z x^2 w punkcie 3 to 2*3 = 6.\n",
      "PyTorch wyliczy\u0142: 6.0\n",
      "\u2705 Autograd dzia\u0142a idealnie!\n"
     ]
    }
   ],
   "source": [
    "# 1. Definiujemy X\n",
    "# WA\u017bNE: requires_grad=True m\u00f3wi PyTorchowi: \"\u015aled\u017a ka\u017cd\u0105 operacj\u0119 na tej zmiennej!\"\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# 2. Definiujemy funkcj\u0119 Y (Symulacja b\u0142\u0119du sieci)\n",
    "# y = x^2 + 5\n",
    "y = x**2 + 5\n",
    "\n",
    "print(f\"X: {x}\")\n",
    "print(f\"Y (Wynik funkcji): {y}\")\n",
    "\n",
    "# 3. MAGIA: Backward Pass (Wsteczna propagacja)\n",
    "# M\u00f3wimy: \"Policz, jak zmiana X wp\u0142ywa na Y\"\n",
    "y.backward()\n",
    "\n",
    "# 4. Sprawdzamy wynik\n",
    "print(\"-\" * 30)\n",
    "print(f\"Matematyka m\u00f3wi: pochodna z x^2 w punkcie 3 to 2*3 = 6.\")\n",
    "print(f\"PyTorch wyliczy\u0142: {x.grad}\")\n",
    "\n",
    "if x.grad == 6.0:\n",
    "    print(\"\u2705 Autograd dzia\u0142a idealnie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5834356",
   "metadata": {},
   "source": [
    "## \ud83e\udde0 Podsumowanie: Po co nam to?\n",
    "\n",
    "W powy\u017cszym przyk\u0142adzie `y = x^2 + 5`:\n",
    "*   **x** to Wagi twojej sieci neuronowej (to, co chcemy poprawi\u0107).\n",
    "*   **y** to B\u0142\u0105d sieci (Loss) - np. r\u00f3\u017cnica mi\u0119dzy tym co sie\u0107 przewidzia\u0142a, a prawd\u0105.\n",
    "\n",
    "Gdy wywo\u0142ujesz `loss.backward()`, PyTorch automatycznie liczy:\n",
    "*\"Jak bardzo musz\u0119 zmieni\u0107 wag\u0119 X, \u017ceby zmniejszy\u0107 b\u0142\u0105d Y?\"*.\n",
    "\n",
    "**Tu jest haczyk.**\n",
    "W GPT-4 masz bilion wag (parametr\u00f3w).\n",
    "R\u0119czne liczenie pochodnych zaj\u0119\u0142oby wieczno\u015b\u0107.\n",
    "PyTorch robi to automatycznie, buduj\u0105c w pami\u0119ci tzw. **Graf Obliczeniowy**. Zapami\u0119tuje, \u017ce `y` powsta\u0142o przez podniesienie `x` do kwadratu, wi\u0119c wie, jak wr\u00f3ci\u0107 po swoich \u015bladach.\n",
    "\n",
    "W nast\u0119pnym notatniku u\u017cyjemy tego, \u017ceby zbudowa\u0107 prawdziw\u0105 sie\u0107 w stylu **Object Oriented Programming**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}