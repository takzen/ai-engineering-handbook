{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/ai-engineering-handbook/blob/main/notebooks/099_Neural_Architecture_Search_NAS.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/ai-engineering-handbook/blob/main/99_Neural_Architecture_Search_NAS.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ed36c",
   "metadata": {},
   "source": [
    "# \ud83e\uddec NAS: Gdy AI projektuje AI (Neural Architecture Search)\n",
    "\n",
    "Projektowanie sieci neuronowych to czarna magia. Dlaczego ResNet ma akurat tyle warstw? Bo kto\u015b tak sprawdzi\u0142 i zadzia\u0142a\u0142o.\n",
    "\n",
    "**NAS (Neural Architecture Search)** automatyzuje ten proces.\n",
    "Traktujemy architektur\u0119 sieci jako **Genom**.\n",
    "*   Genom: `[64, 128, 64]` -> Oznacza sie\u0107 z 3 warstwami ukrytymi o takich rozmiarach.\n",
    "*   Genom: `[16]` -> Malutka sie\u0107 z 1 warstw\u0105.\n",
    "\n",
    "Zastosujemy **Ewolucj\u0119**:\n",
    "1.  **Populacja:** Losujemy 10 r\u00f3\u017cnych architektur.\n",
    "2.  **Fitness:** Trenujemy ka\u017cd\u0105 przez 1 epok\u0119 na MNIST. Wynik Accuracy to jej si\u0142a.\n",
    "3.  **Mutacja:** Bierzemy najlepsz\u0105 sie\u0107 i losowo zmieniamy liczb\u0119 neuron\u00f3w lub dodajemy warstw\u0119."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49463fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urz\u0105dzenie: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Konfiguracja\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "POPULATION_SIZE = 5  # Ma\u0142a populacja dla szybko\u015bci\n",
    "GENERATIONS = 3      # Kr\u00f3tka ewolucja\n",
    "EPOCHS_PER_NET = 1   # Szybki test (tylko 1 epoka)\n",
    "\n",
    "# Dane (MNIST)\n",
    "train_loader = DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=1000, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Urz\u0105dzenie: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ed16d",
   "metadata": {},
   "source": [
    "## Dynamiczna Sie\u0107 (Budowniczy)\n",
    "\n",
    "Musimy napisa\u0107 klas\u0119, kt\u00f3ra nie ma sztywnej struktury w `__init__`.\n",
    "Zamiast tego przyjmuje list\u0119 `architecture` (np. `[100, 50]`) i dynamicznie buduje warstwy za pomoc\u0105 `nn.ModuleList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e58798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przyk\u0142adowa architektura:\n",
      "DynamicNet(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DynamicNet(nn.Module):\n",
    "    def __init__(self, architecture):\n",
    "        super().__init__()\n",
    "        self.architecture = architecture\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Wej\u015bcie: 784 (MNIST 28x28)\n",
    "        input_dim = 784\n",
    "        \n",
    "        # Budujemy warstwy ukryte na podstawie genotypu\n",
    "        for hidden_dim in architecture:\n",
    "            self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim # Wyj\u015bcie tej warstwy to wej\u015bcie nast\u0119pnej\n",
    "            \n",
    "        # Warstwa wyj\u015bciowa (zawsze 10 klas)\n",
    "        self.output_layer = nn.Linear(input_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784) # Sp\u0142aszczamy obrazek\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Test: Stw\u00f3rzmy losow\u0105 sie\u0107\n",
    "dummy_net = DynamicNet([128, 64]) # 2 warstwy\n",
    "print(\"Przyk\u0142adowa architektura:\")\n",
    "print(dummy_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565b587",
   "metadata": {},
   "source": [
    "## Funkcja Oceny (Fitness)\n",
    "\n",
    "To funkcja, kt\u00f3ra:\n",
    "1.  Bierze architektur\u0119 (list\u0119).\n",
    "2.  Buduje model.\n",
    "3.  Trenuje go szybko (1 epoka).\n",
    "4.  Zwraca Accuracy na zbiorze testowym.\n",
    "\n",
    "To b\u0119dzie nasz \"koszt \u017cycia\" dla danego osobnika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deebc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_architecture(arch):\n",
    "    print(f\"\ud83e\uddec Testuj\u0119 architektur\u0119: {arch} ...\", end=\" \")\n",
    "    \n",
    "    # Budowa modelu\n",
    "    model = DynamicNet(arch).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Szybki trening (1 epoka)\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Przerywamy po 100 batchach dla szybko\u015bci demo (opcjonalne)\n",
    "        if batch_idx > 100: break \n",
    "\n",
    "    # Szybka ewaluacja\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            \n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    print(f\"-> Accuracy: {acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca541d7a",
   "metadata": {},
   "source": [
    "## Ewolucja (Search Loop)\n",
    "\n",
    "1.  **Inicjalizacja:** Tworzymy losowe \"mutanty\" (np. `[30]`, `[100, 100]`).\n",
    "2.  **Mutacja:**\n",
    "    *   Zmie\u0144 liczb\u0119 neuron\u00f3w w warstwie (np. $50 \\to 60$).\n",
    "    *   Dodaj now\u0105 warstw\u0119.\n",
    "    *   Usu\u0144 warstw\u0119.\n",
    "\n",
    "Uruchamiamy proces na 3 pokolenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee54527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- POKOLENIE 1 ---\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [38, 38, 87] ... -> Accuracy: 82.71%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [103, 63, 39] ... -> Accuracy: 83.12%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [115] ... -> Accuracy: 87.85%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [58, 47, 62] ... -> Accuracy: 84.56%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [111, 42, 52] ... -> Accuracy: 83.59%\n",
      "Najlepsi w tym pokoleniu: [[115], [58, 47, 62]]\n",
      "\n",
      "--- POKOLENIE 2 ---\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [115] ... -> Accuracy: 88.93%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [58, 47, 62] ... -> Accuracy: 83.35%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [58, 47] ... -> Accuracy: 87.13%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [58, 47, 123, 62] ... -> Accuracy: 82.78%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [154] ... -> Accuracy: 89.01%\n",
      "Najlepsi w tym pokoleniu: [[154], [115]]\n",
      "\n",
      "--- POKOLENIE 3 ---\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [154] ... -> Accuracy: 88.28%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [115] ... -> Accuracy: 88.20%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [38, 154] ... -> Accuracy: 87.34%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [77] ... -> Accuracy: 87.56%\n",
      "\ud83e\uddec Testuj\u0119 architektur\u0119: [157] ... -> Accuracy: 89.10%\n",
      "Najlepsi w tym pokoleniu: [[157], [154]]\n",
      "------------------------------\n",
      "\ud83c\udfc6 ZWYCI\u0118ZCA NAS: [157]\n",
      "Wynik: 89.10%\n"
     ]
    }
   ],
   "source": [
    "# 1. Populacja pocz\u0105tkowa (losowe listy)\n",
    "population = [\n",
    "    [random.randint(32, 128) for _ in range(random.randint(1, 3))]\n",
    "    for _ in range(POPULATION_SIZE)\n",
    "]\n",
    "\n",
    "def mutate(arch):\n",
    "    \"\"\"Dokonuje losowej zmiany w architekturze\"\"\"\n",
    "    new_arch = arch.copy()\n",
    "    choice = random.random()\n",
    "    \n",
    "    if choice < 0.33 and len(new_arch) > 1:\n",
    "        # Usu\u0144 warstw\u0119\n",
    "        new_arch.pop(random.randint(0, len(new_arch)-1))\n",
    "    elif choice < 0.66:\n",
    "        # Zmie\u0144 rozmiar warstwy\n",
    "        idx = random.randint(0, len(new_arch)-1)\n",
    "        new_arch[idx] = int(new_arch[idx] * random.uniform(0.5, 1.5))\n",
    "    else:\n",
    "        # Dodaj warstw\u0119\n",
    "        new_arch.insert(random.randint(0, len(new_arch)), random.randint(32, 128))\n",
    "        \n",
    "    # Zabezpieczenie przed pust\u0105 sieci\u0105\n",
    "    if len(new_arch) == 0: return [32]\n",
    "    return new_arch\n",
    "\n",
    "# G\u0141\u00d3WNA P\u0118TLA NAS\n",
    "best_arch = None\n",
    "best_acc = 0\n",
    "\n",
    "for gen in range(GENERATIONS):\n",
    "    print(f\"\\n--- POKOLENIE {gen+1} ---\")\n",
    "    scores = []\n",
    "    \n",
    "    # Ocena ca\u0142ej populacji\n",
    "    for arch in population:\n",
    "        acc = evaluate_architecture(arch)\n",
    "        scores.append((acc, arch))\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_arch = arch\n",
    "    \n",
    "    # Selekcja (Bierzemy 2 najlepsze)\n",
    "    scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    survivors = [x[1] for x in scores[:2]]\n",
    "    \n",
    "    print(f\"Najlepsi w tym pokoleniu: {survivors}\")\n",
    "    \n",
    "    # Reprodukcja (Mutacja zwyci\u0119zc\u00f3w)\n",
    "    new_population = list(survivors) # Elityzm (zostawiamy najlepszych)\n",
    "    while len(new_population) < POPULATION_SIZE:\n",
    "        parent = random.choice(survivors)\n",
    "        child = mutate(parent)\n",
    "        new_population.append(child)\n",
    "        \n",
    "    population = new_population\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"\ud83c\udfc6 ZWYCI\u0118ZCA NAS: {best_arch}\")\n",
    "print(f\"Wynik: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d333f078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trenowanie zwyci\u0119skiej architektury do pe\u0142na...\n",
      "Gotowe. AI zaprojektowa\u0142o sobie m\u00f3zg.\n"
     ]
    }
   ],
   "source": [
    "# Trenujemy zwyci\u0119zc\u0119 \"na powa\u017cnie\" (d\u0142u\u017cej)\n",
    "print(\"Trenowanie zwyci\u0119skiej architektury do pe\u0142na...\")\n",
    "final_model = DynamicNet(best_arch).to(DEVICE)\n",
    "# ... tu by\u015bmy zrobili normalny trening na 10 epok\n",
    "print(\"Gotowe. AI zaprojektowa\u0142o sobie m\u00f3zg.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904cd08",
   "metadata": {},
   "source": [
    "## \ud83e\udde0 Podsumowanie: AutoML\n",
    "\n",
    "To, co zrobili\u015bmy, to uproszczona wersja algorytm\u00f3w takich jak **EfficientNet** (kt\u00f3ry zosta\u0142 zaprojektowany przez Google AutoML, a nie cz\u0142owieka).\n",
    "\n",
    "**Zalety NAS:**\n",
    "1.  Znajduje nieoczywiste architektury (np. bardzo w\u0105skie, ale g\u0142\u0119bokie).\n",
    "2.  Oszcz\u0119dza czas in\u017cyniera (ale kosztuje czas GPU).\n",
    "\n",
    "**Wady:**\n",
    "1.  Jest ekstremalnie kosztowny obliczeniowo (trzeba wytrenowa\u0107 setki modeli). Dlatego w praktyce u\u017cywa si\u0119 \"One-Shot NAS\" (wsp\u00f3\u0142dzielenie wag mi\u0119dzy modelami), \u017ceby nie trenowa\u0107 od zera."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-handbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}