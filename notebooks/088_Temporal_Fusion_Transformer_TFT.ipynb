{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/ai-engineering-handbook/blob/main/notebooks/088_Temporal_Fusion_Transformer_TFT.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/ai-engineering-handbook/blob/main/88_Temporal_Fusion_Transformer_TFT.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a22544",
   "metadata": {},
   "source": [
    "# \u23f3 TFT: Transformer do zada\u0144 specjalnych (Time Series)\n",
    "\n",
    "Standardowy Transformer (GPT) traktuje wszystko jako tekst.\n",
    "TFT jest zaprojektowany specjalnie dla liczb i czasu.\n",
    "\n",
    "Rozwi\u0105zuje problem **Heterogenicznych Danych**:\n",
    "1.  **Zmienne statyczne:** (ID sklepu, lokalizacja) -> Nie zmieniaj\u0105 si\u0119 w czasie.\n",
    "2.  **Zmienne dynamiczne znane:** (Dzie\u0144 tygodnia, \u015awi\u0119ta) -> Znamy je na rok do przodu.\n",
    "3.  **Zmienne dynamiczne nieznane:** (Sprzeda\u017c) -> Znamy tylko przesz\u0142o\u015b\u0107.\n",
    "\n",
    "**Kluczowa innowacja: Gating (Bramkowanie).**\n",
    "Wi\u0119kszo\u015b\u0107 sieci neuronowych to \"czarne skrzynki\". TFT u\u017cywa mechanizmu **GLU (Gated Linear Unit)**, kt\u00f3ry dzia\u0142a jak kran. Mo\u017ce ca\u0142kowicie odci\u0105\u0107 dop\u0142yw informacji z danej kolumny, je\u015bli uzna j\u0105 za szum.\n",
    "\n",
    "Zbudujemy od zera serce TFT: **Gated Residual Network (GRN)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5be9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urz\u0105dzenie: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Konfiguracja\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "HIDDEN_DIM = 64  # Rozmiar ukryty (dla ka\u017cdego feature'a)\n",
    "DROPOUT = 0.1\n",
    "\n",
    "print(f\"Urz\u0105dzenie: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90df7c",
   "metadata": {},
   "source": [
    "## Krok 1: GLU (Gated Linear Unit)\n",
    "\n",
    "To prosty, ale genialny mechanizm.\n",
    "$$ GLU(x) = \\sigma(W_1 x + b_1) \\odot (W_2 x + b_2) $$\n",
    "\n",
    "*   Cz\u0119\u015b\u0107 prawa ($W_2 x$): Przetwarza dane (Informacja).\n",
    "*   Cz\u0119\u015b\u0107 lewa ($\\sigma(...)$): Sigmoid zwraca warto\u015bci 0-1 (Bramka).\n",
    "\n",
    "Mno\u017cymy Informacj\u0119 przez Bramk\u0119. Je\u015bli Bramka = 0, informacja znika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58ca468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wej\u015bcie: torch.Size([5, 64])\n",
      "Wyj\u015bcie: torch.Size([5, 64]) (Wymiar zachowany, ale przefiltrowany)\n"
     ]
    }
   ],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        # Wersja PyTorchowa GLU oczekuje wej\u015bcia 2x wi\u0119kszego, \n",
    "        # bo dzieli je na p\u00f3\u0142 (jedna po\u0142owa to dane, druga to bramka).\n",
    "        self.linear = nn.Linear(input_dim, input_dim * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Dim]\n",
    "        val = self.linear(x)\n",
    "        # F.glu dzieli tensor na p\u00f3\u0142 i robi: A * sigmoid(B)\n",
    "        return F.glu(val, dim=-1)\n",
    "\n",
    "# Test\n",
    "glu = GLU(HIDDEN_DIM)\n",
    "dummy = torch.randn(5, HIDDEN_DIM)\n",
    "out = glu(dummy)\n",
    "print(f\"Wej\u015bcie: {dummy.shape}\")\n",
    "print(f\"Wyj\u015bcie: {out.shape} (Wymiar zachowany, ale przefiltrowany)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f8b6c",
   "metadata": {},
   "source": [
    "## Krok 2: GRN (Gated Residual Network)\n",
    "\n",
    "To jest podstawowy klocek TFT (u\u017cywany wsz\u0119dzie).\n",
    "Sk\u0142ada si\u0119 z:\n",
    "1.  **Skip Connection:** Orygina\u0142 dodawany na ko\u0144cu (pami\u0119tasz ResNet?).\n",
    "2.  **LayerNorm:** Stabilizacja.\n",
    "3.  **Dwie warstwy Linear + ELU:** Nieliniowe przetwarzanie.\n",
    "4.  **GLU:** Bramkowanie na ko\u0144cu.\n",
    "5.  **Context (Optional):** GRN mo\u017ce przyjmowa\u0107 dodatkowy wektor kontekstu (np. \"To jest Sklep nr 5\"), kt\u00f3ry wp\u0142ywa na przetwarzanie.\n",
    "\n",
    "$$ GRN(x, c) = LayerNorm(x + GLU(Linear(ELU(Linear(x, c))))) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c435b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRN Output: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "class GRN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, context_dim=None):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Warstwa 1\n",
    "        # Je\u015bli mamy kontekst, doklejamy go (lub rzutujemy)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        if context_dim is not None:\n",
    "            self.context_projection = nn.Linear(context_dim, hidden_dim, bias=False)\n",
    "            \n",
    "        # Warstwa 2\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Bramka i Normalizacja\n",
    "        self.glu = GLU(hidden_dim)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # Projekcja rezydualna (je\u015bli wej\u015bcie ma inny wymiar ni\u017c wyj\u015bcie)\n",
    "        self.skip_projection = nn.Linear(input_dim, hidden_dim) if input_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x, context=None):\n",
    "        # x: [Batch, Input_Dim]\n",
    "        residual = self.skip_projection(x)\n",
    "        \n",
    "        # 1. Pierwsza warstwa + Kontekst\n",
    "        x = self.fc1(x)\n",
    "        if context is not None:\n",
    "            # Dodajemy kontekst (np. wektor statyczny sklepu) do przetwarzania\n",
    "            x = x + self.context_projection(context)\n",
    "            \n",
    "        x = F.elu(x) # Exponential Linear Unit (standard w TFT)\n",
    "        \n",
    "        # 2. Druga warstwa\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # 3. Bramkowanie (GLU) + Dropout\n",
    "        x = F.dropout(x, p=DROPOUT, training=self.training)\n",
    "        x = self.glu(x)\n",
    "        \n",
    "        # 4. Add & Norm\n",
    "        return self.norm(x + residual)\n",
    "\n",
    "# Test z Kontekstem\n",
    "grn = GRN(input_dim=10, hidden_dim=64, context_dim=5)\n",
    "x_in = torch.randn(32, 10) # 32 pr\u00f3bki, 10 cech\n",
    "c_in = torch.randn(32, 5)  # Kontekst (np. ID sklepu)\n",
    "\n",
    "out = grn(x_in, c_in)\n",
    "print(f\"GRN Output: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b8790",
   "metadata": {},
   "source": [
    "## Krok 3: Variable Selection Network (VSN)\n",
    "\n",
    "To jest unikalne dla TFT.\n",
    "Zamiast wrzuca\u0107 wszystkie cechy do jednego worka (jak w MLP), TFT przetwarza **ka\u017cd\u0105 kolumn\u0119 osobno** przez w\u0142asny GRN.\n",
    "Na ko\u0144cu sie\u0107 decyduje (wa\u017cy), kt\u00f3re kolumny s\u0105 wa\u017cne dla danej pr\u00f3bki.\n",
    "\n",
    "Dzi\u0119ki temu TFT jest **Interpretowalny**. Powie Ci: *\"Dla tej prognozy wzi\u0119\u0142am pod uwag\u0119 80% Sprzeda\u017cy Wczorajszej i 20% Pogody, a zignorowa\u0142am Dzie\u0144 Tygodnia\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836e5417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyj\u015bcie VSN: torch.Size([32, 64]) -> Jeden wektor reprezentuj\u0105cy ca\u0142y krok czasowy.\n",
      "--- WAGI WA\u017bNO\u015aCI (Feature Importance) dla pierwszego przyk\u0142adu ---\n",
      "[0.08056269 0.12061661 0.79882073]\n"
     ]
    }
   ],
   "source": [
    "class VariableSelectionNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, input_dim, hidden_dim, context_dim=None):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs # Ile mamy kolumn (zmiennych)?\n",
    "        \n",
    "        # Dla ka\u017cdej zmiennej tworzymy osobny GRN\n",
    "        self.single_variable_grns = nn.ModuleList([\n",
    "            GRN(input_dim, hidden_dim, context_dim) for _ in range(num_inputs)\n",
    "        ])\n",
    "        \n",
    "        # GRN wa\u017c\u0105cy (decyduje o wagach dla ka\u017cdej zmiennej)\n",
    "        # Wej\u015bcie to sp\u0142aszczone wszystkie zmienne\n",
    "        self.weighting_grn = GRN(num_inputs * input_dim, num_inputs, context_dim)\n",
    "        \n",
    "    def forward(self, x_list, context=None):\n",
    "        # x_list: Lista tensor\u00f3w (ka\u017cdy to jedna zmienna np. [Batch, 1])\n",
    "        # Musimy je najpierw zrzutowa\u0107 na ten sam wymiar (Embedding), tu pomijamy dla uproszczenia\n",
    "        # Zak\u0142adamy, \u017ce x_list to tensor [Batch, Num_Inputs, Input_Dim]\n",
    "        \n",
    "        batch_size = x_list.shape[0]\n",
    "        \n",
    "        # 1. Przetwarzamy ka\u017cd\u0105 zmienn\u0105 przez jej GRN\n",
    "        processed_vars = []\n",
    "        for i in range(self.num_inputs):\n",
    "            var_out = self.single_variable_grns[i](x_list[:, i, :], context)\n",
    "            processed_vars.append(var_out)\n",
    "            \n",
    "        processed_vars = torch.stack(processed_vars, dim=1) # [Batch, Num, Hidden]\n",
    "        \n",
    "        # 2. Obliczamy wagi wa\u017cno\u015bci (Weights)\n",
    "        # Sp\u0142aszczamy wej\u015bcie dla Weighting GRN\n",
    "        flat_input = x_list.view(batch_size, -1)\n",
    "        weights = self.weighting_grn(flat_input, context)\n",
    "        weights = F.softmax(weights, dim=-1) # [Batch, Num_Inputs]\n",
    "        \n",
    "        # 3. Suma wa\u017cona\n",
    "        # weights: [Batch, Num, 1]\n",
    "        weights = weights.unsqueeze(-1)\n",
    "        combined = torch.sum(processed_vars * weights, dim=1)\n",
    "        \n",
    "        return combined, weights\n",
    "\n",
    "# Symulacja: Mamy 3 zmienne (np. Sprzeda\u017c, Pogoda, Cena), ka\u017cda ma wymiar 64 (po embeddingu)\n",
    "vsn = VariableSelectionNetwork(num_inputs=3, input_dim=64, hidden_dim=64)\n",
    "\n",
    "dummy_vars = torch.randn(32, 3, 64) # [Batch, Zmienne, Cechy]\n",
    "out, weights = vsn(dummy_vars)\n",
    "\n",
    "print(f\"Wyj\u015bcie VSN: {out.shape} -> Jeden wektor reprezentuj\u0105cy ca\u0142y krok czasowy.\")\n",
    "print(\"--- WAGI WA\u017bNO\u015aCI (Feature Importance) dla pierwszego przyk\u0142adu ---\")\n",
    "print(weights[0].squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39215b8f",
   "metadata": {},
   "source": [
    "## \ud83e\udde0 Podsumowanie: Dlaczego TFT jest SOTA?\n",
    "\n",
    "TFT \u0142\u0105czy zalety wszystkich \u015bwiat\u00f3w:\n",
    "1.  **RNN (LSTM):** U\u017cywa ich do lokalnego przetwarzania sekwencji (nie pokazali\u015bmy tego tutaj, ale s\u0105 w pe\u0142nej architekturze).\n",
    "2.  **Transformer (Attention):** U\u017cywa Multi-Head Attention do patrzenia na d\u0142ugoterminowe zale\u017cno\u015bci (np. \"sprzeda\u017c rok temu\").\n",
    "3.  **Drzewa Decyzyjne (Selection):** Dzi\u0119ki `VariableSelectionNetwork` potrafi odrzuca\u0107 szum, co zwykle robi\u0105 XGBoosty.\n",
    "\n",
    "Dlatego TFT wygrywa konkursy forecastingowe (np. M5 Competition) i jest u\u017cywany w Google Cloud Forecasting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-handbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}