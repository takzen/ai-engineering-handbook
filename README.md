# üìò Podrƒôcznik In≈ºynierii AI & Implementacje Referencyjne

Kompleksowy zbi√≥r algorytm√≥w zaimplementowanych od podstaw ("from first principles"), pokrywajƒÖcy pe≈Çne spektrum In≈ºynierii Uczenia Maszynowego: od Analizy Statystycznej i Klasycznego ML, a≈º po Du≈ºe Modele Jƒôzykowe (LLM) i architektury Computer Vision.

### üéØ Cel Repozytorium

Ten projekt s≈Çu≈ºy jako **referencja techniczna** oraz baza wiedzy demonstrujƒÖca matematyczne fundamenty stojƒÖce za nowoczesnymi systemami AI. Wykracza poza u≈ºywanie gotowych, wysokopoziomowych API, skupiajƒÖc siƒô na zrozumieniu tego, _jak_ i _dlaczego_ te algorytmy dzia≈ÇajƒÖ "pod maskƒÖ".

### üîë Kluczowe Implementacje (Od Zera)

- **Architektura LLM:** Pe≈Çna implementacja Bloku Transformera (Self-Attention, LayerNorm, Residuals) w PyTorch + Positional Encoding + Flash Attention & KV Cache.
- **Optymalizacja:** Matematyczna implementacja LoRA (Low-Rank Adaptation) do fine-tuningu + Kwantyzacja (FP32 ‚Üí INT8) + Product Quantization dla baz wektorowych.
- **Generative AI:** Sieci GAN, VAE (z wykorzystaniem Reparameterization Trick) oraz Diffusion Models (DDPM).
- **Computer Vision:** Rƒôczna implementacja mechanizm√≥w IoU (Intersection over Union), NMS (Non-Max Suppression) oraz Vision Transformers (ViT).
- **ML Ops:** Niestandardowe Estymatory (Custom Estimators) i Pipeline'y Scikit-Learn do produkcyjnego przetwarzania danych.
- **Advanced ML:** Metric Learning (Siamese Networks), Graph Neural Networks, Contrastive Learning, Data Drift Detection.
- **Agenci AI:** LangChain ReAct, Prompt Engineering (CoT/ToT), RAG Evaluation, Speculative Decoding.
- **Next-Gen Architectures:** Mamba (State Space Models), Mixture of Experts (MoE), Liquid Neural Networks, Meta-Learning (MAML).

---

## üìÇ Spis Tre≈õci i Tematyka

### üìä Analiza Danych (EDA) i Statystyka

Fundamenty pracy z danymi. Jak zrozumieƒá, co siedzi w tabeli, zanim wrzucimy to do modelu.

| Plik                                                   | Temat                   | Kluczowe pojƒôcia                                                   |
| :----------------------------------------------------- | :---------------------- | :----------------------------------------------------------------- |
| **00_KDE_Tutorial.ipynb**                              | Rozk≈Çady danych         | Kernel Density Estimation (KDE), histogramy, wizualizacja gƒôsto≈õci |
| **01_Correlations_and_Significance_of_Features.ipynb** | Badanie zale≈ºno≈õci      | Korelacja Pearsona/Spearmana, Heatmapy, p-value                    |
| **04_Statistics_and_Scaling.ipynb**                    | Testy hipotez i skala   | **P-value**, Test T-studenta, MinMaxScaler vs StandardScaler       |
| **35_ANOVA_Hypothesis_Testing.ipynb**                  | Por√≥wnywanie grup       | ANOVA, Test F, wariancja miƒôdzygrupowa                             |
| **42_Statistics_Masterclass.ipynb**                    | Statystyka zaawansowana | Testy parametryczne i nieparametryczne, rozk≈Çady                   |

### üõ†Ô∏è In≈ºynieria Cech (Feature Engineering)

Przygotowanie "brudnych" danych, aby algorytmy mog≈Çy z nich korzystaƒá.

| Plik                                    | Temat                    | Kluczowe pojƒôcia                                                        |
| :-------------------------------------- | :----------------------- | :---------------------------------------------------------------------- |
| **02_Advanced_Feature_Selection.ipynb** | Wyb√≥r najlepszych danych | RFE (Recursive Feature Elimination), SelectKBest, redukcja szumu        |
| **03_Encoding_Tutorial.ipynb**          | Zamiana tekstu na liczby | One-Hot Encoding, Label Encoding, Ordinal Encoding                      |
| **13_Missing_Data_Imputation.ipynb**    | Obs≈Çuga brak√≥w danych    | Imputacja (≈õrednia, mediana), imputacja grupowa (Pandas transform), NaN |

### ü§ñ Klasyczny Machine Learning

Algorytmy uczenia z nadzorem (Supervised) i bez nadzoru (Unsupervised).

| Plik                                          | Temat                    | Kluczowe pojƒôcia                                                      |
| :-------------------------------------------- | :----------------------- | :-------------------------------------------------------------------- |
| **06_Naive_Bayes_Spam.ipynb**                 | Filtr antyspamowy (NLP)  | **Naive Bayes**, Bag of Words, prawdopodobie≈Ñstwo warunkowe           |
| **08_Overfitting_Underfitting.ipynb**         | Diagnoza b≈Çƒôd√≥w modelu   | Przeuczenie vs Niedouczenie, wielomiany, generalizacja                |
| **09_K_Means_Clustering.ipynb**               | Segmentacja klient√≥w     | **Unsupervised Learning**, K-Means, Metoda ≈Åokcia (Elbow Method)      |
| **10_Decision_Trees.ipynb**                   | Drzewa Decyzyjne         | White-Box Models, wizualizacja decyzji, Feature Importance            |
| **14_Random_Forest_Ensemble.ipynb**           | Ensemble Learning        | **Random Forest**, Bagging, agregacja predykcji, stabilno≈õƒá           |
| **19_Cross_Validation.ipynb**                 | Walidacja modeli         | **K-Fold**, walidacja krzy≈ºowa, unikanie overfittingu                 |
| **27_Hyperparameter_Tuning_GridSearch.ipynb** | Optymalizacja modeli     | **Grid Search**, RandomizedSearch, dob√≥r parametr√≥w                   |
| **34_Regularization_Lasso_Ridge.ipynb**       | Regularyzacja            | **Lasso (L1)**, Ridge (L2), ElasticNet, kara za z≈Ço≈ºono≈õƒá             |
| **36_Market_Basket_Apriori.ipynb**            | Analiza Koszykowa        | **Apriori**, Support, Confidence, Lift, regu≈Çy asocjacyjne            |
| **37_Gradient_Boosting_XGBoost.ipynb**        | Gradient Boosting        | **XGBoost**, LightGBM, uczenie sekwencyjne, boosting                  |
| **47_SVM_Kernel_Trick.ipynb**                 | Support Vector Machines  | **SVM**, Kernel Trick, hyperplanes, separowalno≈õƒá liniowa             |
| **51_Recommender_Systems_SVD.ipynb**          | Systemy Rekomendacyjne   | **SVD**, Matrix Factorization, collaborative filtering                |
| **60_Bayesian_Optimization_Optuna.ipynb**     | Optymalizacja Bayesowska | **Optuna**, Bayesian Optimization, inteligentny dob√≥r hiperparametr√≥w |

### üìè Ewaluacja Modeli

Jak sprawdziƒá, czy model naprawdƒô dzia≈Ça?

| Plik                                           | Temat           | Kluczowe pojƒôcia                                                            |
| :--------------------------------------------- | :-------------- | :-------------------------------------------------------------------------- |
| **07_Confusion_Matrix_Precision_Recall.ipynb** | Metryki sukcesu | **Macierz Pomy≈Çek**, Precision, Recall, F1-Score (dlaczego Accuracy k≈Çamie) |

### üß† Fundamenty LLM i Generative AI

Mechanizmy stojƒÖce za modelami takimi jak GPT.

| Plik                                         | Temat                          | Kluczowe pojƒôcia                                                                      |
| :------------------------------------------- | :----------------------------- | :------------------------------------------------------------------------------------ |
| **05_Top_p_Top_k.ipynb**                     | Sterowanie generowaniem tekstu | Sampling, probabilistyka wyboru s≈Ç√≥w, kreatywno≈õƒá AI                                  |
| **11_Embeddings_Vector_Space.ipynb**         | Wektory s≈Ç√≥w                   | **Embeddings**, przestrze≈Ñ wektorowa, algebra na s≈Çowach (Kr√≥l - Mƒô≈ºczyzna + Kobieta) |
| **12_LLM_Temperature.ipynb**                 | Parametr Temperatury           | Softmax, Logits, sterowanie halucynacjami i pewno≈õciƒÖ modelu                          |
| **23_Tokenization_GPT.ipynb**                | Tokenizacja                    | **Byte Pair Encoding**, subword tokenization, problem z liczeniem liter               |
| **24_Self_Attention_Mechanism.ipynb**        | Mechanizm Uwagi                | **Transformer**, Query-Key-Value, kontekst w zdaniach                                 |
| **18_Cosine_Similarity_Search.ipynb**        | Podobie≈Ñstwo wektor√≥w          | **Cosine Similarity**, kƒÖt vs odleg≈Ço≈õƒá, Semantic Search                              |
| **20_RAG_Architecture_Simulation.ipynb**     | Retrieval Augmented Generation | **RAG**, wyszukiwanie w bazie wiedzy, pipeline z embeddingami                         |
| **26_RAG_Chunking_Strategies.ipynb**         | Przygotowanie dokument√≥w       | **Chunking**, Fixed-size, Recursive, Overlap, Windowing                               |
| **46_Transformer_Block_From_Scratch.ipynb**  | Blok Transformera              | **Transformer Block**, LayerNorm, Residual Connections, Feed Forward                  |
| **55_LoRA_Fine_Tuning_Math.ipynb**           | Fine-tuning LLM                | **LoRA**, Low-Rank Adaptation, efektywne douczanie modeli                             |
| **56_Positional_Encoding_Transformer.ipynb** | GPS Transformera               | **Positional Encoding**, sinusy i cosinusy, kolejno≈õƒá w sekwencjach                   |
| **64_Knowledge_Distillation.ipynb**          | Kompresja modeli               | **Teacher-Student**, Soft Labels, Temperature, transfer wiedzy                        |
| **68_RLHF_PPO_ChatGPT_Alignment.ipynb**      | Alignment LLM                  | **PPO**, RLHF, uczenie przez feedback ludzki, jak powsta≈Ç ChatGPT                     |

### üöÄ Optymalizacja LLM i Next-Gen Architectures

Nowoczesne architektury i techniki optymalizacji dla produkcyjnych system√≥w AI.

| Plik                                    | Temat                      | Kluczowe pojƒôcia                                                           |
| :-------------------------------------- | :------------------------- | :------------------------------------------------------------------------- |
| **71_LLM_Optimization_KV_Cache.ipynb**  | Flash Attention & KV Cache | **KV Cache**, Flash Attention, Tiling, optymalizacja O(N¬≤), pamiƒôƒá GPU     |
| **72_Mamba_State_Space_Models.ipynb**   | State Space Models         | **Mamba**, SSM, dyskretyzacja r√≥wna≈Ñ r√≥≈ºniczkowych, z≈Ço≈ºono≈õƒá liniowa      |
| **73_Mixture_of_Experts_MoE.ipynb**     | Mixture of Experts         | **MoE**, Gating Network, Router, architektura GPT-4, sparse models         |
| **74_Liquid_Neural_Networks_LFC.ipynb** | Liquid Neural Networks     | **LFC**, adaptive weights, r√≥wnania r√≥≈ºniczkowe, robotyka, drony           |
| **75_Meta_Learning_MAML.ipynb**         | Meta-Learning              | **MAML**, Model-Agnostic Meta-Learning, few-shot learning, fast adaptation |

### ü§ñ Agenci AI i LLM Engineering

Najgorƒôtszy temat 2025 roku. AI, kt√≥re "dzia≈Ça", a nie tylko "gada".

| Plik                                                 | Temat                        | Kluczowe pojƒôcia                                                        |
| :--------------------------------------------------- | :--------------------------- | :---------------------------------------------------------------------- |
| **76_LangChain_ReAct_Agent.ipynb**                   | Agenci AI                    | **ReAct**, Reason+Act, pƒôtla agenta, narzƒôdzia, akcje                   |
| **77_Prompt_Engineering_CoT_ToT.ipynb**              | Prompt Engineering           | **Chain of Thought**, Tree of Thoughts, reasoning, my≈õlenie na g≈Ços     |
| **78_RAG_Evaluation_RAGAS.ipynb**                    | Ewaluacja RAG                | **RAGAS**, Faithfulness, Answer Relevance, metryki jako≈õci RAG          |
| **79_Vector_Compression_Product_Quantization.ipynb** | Vector Database Optimization | **Product Quantization**, IVF-PQ, FAISS, kompresja wektor√≥w, skalowanie |
| **80_Speculative_Decoding.ipynb**                    | Przyspieszanie Inferencji    | **Speculative Decoding**, draft model, verification, 2-3x speedup       |

### üßÆ Matematyka i Optymalizacja

Jak maszyny siƒô uczƒÖ pod maskƒÖ?

| Plik                                              | Temat               | Kluczowe pojƒôcia                                                      |
| :------------------------------------------------ | :------------------ | :-------------------------------------------------------------------- |
| **15_Gradient_Descent.ipynb**                     | Optymalizacja       | **Gradient Descent**, Learning Rate, schodzenie po gradiencie         |
| **17_PCA_Dimensionality_Reduction.ipynb**         | Redukcja wymiar√≥w   | **PCA**, Principal Component Analysis, wizualizacja wysokich wymiar√≥w |
| **48_tSNE_vs_PCA_Dimensionality_Reduction.ipynb** | Redukcja nieliniowa | **t-SNE**, UMAP, wizualizacja embedding√≥w                             |

### üî¨ Sieci Neuronowe i Deep Learning

Od pojedynczego neuronu do g≈Çƒôbokich sieci.

| Plik                                            | Temat                           | Kluczowe pojƒôcia                                                 |
| :---------------------------------------------- | :------------------------------ | :--------------------------------------------------------------- |
| **16_Neural_Network_Perceptron.ipynb**          | Pierwszy neuron                 | **Perceptron**, wagi, bias, funkcja aktywacji                    |
| **21_MLP_Neural_Network_XOR.ipynb**             | Sieci wielowarstwowe            | **Multi-Layer Perceptron**, warstwy ukryte, XOR problem          |
| **22_Activation_Functions.ipynb**               | Funkcje aktywacji               | **ReLU**, Sigmoid, Softmax, nieliniowo≈õƒá                         |
| **32_PyTorch_Tensors_Autograd.ipynb**           | Podstawy PyTorch                | **Tensors**, Autograd, automatyczne r√≥≈ºniczkowanie               |
| **33_PyTorch_Neural_Network_Class.ipynb**       | Budowa sieci w PyTorch          | **nn.Module**, forward pass, OOP w deep learningu                |
| **38_CNN_Computer_Vision.ipynb**                | Sieci Konwolucyjne              | **CNN**, Conv2d, MaxPool, filtry, Computer Vision                |
| **39_RNN_LSTM_Sequence_Models.ipynb**           | Sieci Rekurencyjne              | **RNN**, LSTM, przetwarzanie sekwencji, pamiƒôƒá                   |
| **40_Autoencoder_Anomaly_Detection.ipynb**      | Detekcja Anomalii               | **Autoencoder**, kompresja, detekcja outlier√≥w                   |
| **41_GAN_Generative_Adversarial_Network.ipynb** | Generative Adversarial Networks | **GAN**, Generator, Dyskryminator, generowanie danych            |
| **43_VAE_Variational_Autoencoder.ipynb**        | Variational Autoencoder         | **VAE**, Latent Space, KL Divergence, generowanie                |
| **49_Object_Detection_IoU.ipynb**               | Detekcja Obiekt√≥w               | **IoU**, Intersection over Union, bounding boxes                 |
| **50_UNet_Image_Segmentation.ipynb**            | Segmentacja Obrazu              | **U-Net**, segmentacja pikselowa, architektura U                 |
| **61_Normalization_Layers_BN_vs_LN.ipynb**      | Warstwy Normalizacji            | **Batch Norm**, Layer Norm, Instance Norm, stabilizacja treningu |
| **70_Vision_Transformer_ViT.ipynb**             | Vision Transformers             | **ViT**, Patches, koniec ery CNN, Self-Attention w obrazach      |

### üéÆ Reinforcement Learning

Uczenie przez nagrody i kary.

| Plik                                  | Temat           | Kluczowe pojƒôcia                               |
| :------------------------------------ | :-------------- | :--------------------------------------------- |
| **44_RL_Q_Learning_FrozenLake.ipynb** | Q-Learning      | **Q-Table**, R√≥wnanie Bellmana, nagrody i kary |
| **45_RL_Deep_Q_Learning_DQN.ipynb**   | Deep Q-Learning | **DQN**, Replay Buffer, sieci neuronowe w RL   |

### üß¨ Algorytmy Zaawansowane

Specjalistyczne techniki i podej≈õcia.

| Plik                                       | Temat                  | Kluczowe pojƒôcia                                                     |
| :----------------------------------------- | :--------------------- | :------------------------------------------------------------------- |
| **52_Genetic_Algorithms_Evolution.ipynb**  | Algorytmy Genetyczne   | **Evolutionary Algorithms**, krzy≈ºowanie, mutacja, selekcja          |
| **53_Monte_Carlo_Simulation.ipynb**        | Symulacje Monte Carlo  | Symulacje probabilistyczne, analiza ryzyka                           |
| **54_FFT_Signal_Processing.ipynb**         | Przetwarzanie Sygna≈Ç√≥w | **FFT**, Transformata Fouriera, analiza czƒôstotliwo≈õci               |
| **59_Model_Quantization_INT8.ipynb**       | Kwantyzacja Modeli     | **Quantization**, FP32‚ÜíINT8, kompresja, odpalanie AI na edge devices |
| **62_Time_Series_Decomposition_STL.ipynb** | Dekompozycja Szereg√≥w  | **STL**, Trend, Sezonowo≈õƒá, Reszta, analiza biznesowa                |

### üé® Generative AI - Zaawansowane

Modele generatywne nowej generacji.

| Plik                                     | Temat                | Kluczowe pojƒôcia                                                 |
| :--------------------------------------- | :------------------- | :--------------------------------------------------------------- |
| **63_Diffusion_Models_DDPM.ipynb**       | Diffusion Models     | **DDPM**, Forward/Reverse Diffusion, matematyka Stable Diffusion |
| **67_Contrastive_Learning_SimCLR.ipynb** | Contrastive Learning | **SimCLR**, uczenie kontrastowe, Self-Supervised Learning        |

### üï∏Ô∏è Graph Neural Networks

Dane w formie graf√≥w i relacji.

| Plik                                   | Temat                 | Kluczowe pojƒôcia                                                 |
| :------------------------------------- | :-------------------- | :--------------------------------------------------------------- |
| **58_Graph_Neural_Networks_GNN.ipynb** | Graph Neural Networks | **GNN**, Message Passing, macierze przyleg≈Ço≈õci, sieci spo≈Çeczne |

### üîç Metric Learning & Similarity

Uczenie odleg≈Ço≈õci i podobie≈Ñstwa.

| Plik                                 | Temat            | Kluczowe pojƒôcia                                                  |
| :----------------------------------- | :--------------- | :---------------------------------------------------------------- |
| **57_Metric_Learning_Siamese.ipynb** | Siamese Networks | **Triplet Loss**, Metric Learning, FaceID, weryfikacja to≈ºsamo≈õci |

### üîß Vector Search & Optimization

Efektywne wyszukiwanie w wysokich wymiarach.

| Plik                                   | Temat              | Kluczowe pojƒôcia                                             |
| :------------------------------------- | :----------------- | :----------------------------------------------------------- |
| **65_HNSW_Vector_Search_Engine.ipynb** | Vector Search      | **HNSW**, Hierarchical Navigable Small World, bazy wektorowe |
| **66_Kalman_Filter_Tracking.ipynb**    | ≈öledzenie Obiekt√≥w | **Kalman Filter**, filtracja predykcyjna, GPS, robotyka      |

### üìà MLOps & Production

Monitoring i wdro≈ºenia produkcyjne.

| Plik                                         | Temat                  | Kluczowe pojƒôcia                                               |
| :------------------------------------------- | :--------------------- | :------------------------------------------------------------- |
| **25_Model_Persistence_Pickle_Joblib.ipynb** | Zapisywanie modeli     | **Pickle**, Joblib, serializacja obiekt√≥w                      |
| **30_Sklearn_Pipelines.ipynb**               | RurociƒÖgi ML           | **Pipeline**, StandardScaler, data leakage prevention          |
| **31_Custom_Transformers.ipynb**             | W≈Çasne transformery    | **BaseEstimator**, TransformerMixin, fit-transform pattern     |
| **28_Python_Dataclasses_for_ML.ipynb**       | Konfiguracja modeli    | **Dataclasses**, structured configs, TrainingArguments pattern |
| **29_OOP_Classmethod_Staticmethod.ipynb**    | Wzorce projektowe      | **@classmethod**, @staticmethod, ModelLoader, factory pattern  |
| **69_Data_Drift_Detection_PSI.ipynb**        | Monitoring Produkcyjny | **Data Drift**, KS-Test, PSI, wykrywanie zmian w danych        |

---

## üõ†Ô∏è Technologie

Projekt oparty na standardowym stacku Data Science:

- **Python 3.x**
- **Pandas & NumPy** (Manipulacja danymi i obliczenia)
- **Scikit-Learn** (Algorytmy ML, Preprocessing, Metryki)
- **Matplotlib & Seaborn** (Wizualizacja danych)
- **SciPy** (Testy statystyczne)
- **PyTorch** (Deep Learning Framework)
- **Optuna** (Bayesian Optimization)

## üöÄ Jak u≈ºywaƒá tego podrƒôcznika?

Masz dwie mo≈ºliwo≈õci uruchomienia kodu: szybkƒÖ (w chmurze) i profesjonalnƒÖ (lokalnie).

### ‚òÅÔ∏è Opcja 1: Google Colab (Bez instalacji)

Najszybszy spos√≥b na naukƒô. Ka≈ºdy notatnik w tym repozytorium posiada przycisk **"Open in Colab"** na samej g√≥rze.

1.  Otw√≥rz wybrany plik `.ipynb` na li≈õcie plik√≥w.
2.  Kliknij przycisk <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" style="vertical-align: middle">.
3.  Kod uruchomi siƒô natychmiast na darmowych GPU od Google.

### üíª Opcja 2: Lokalnie (VS Code + uv)

Zalecane dla in≈ºynier√≥w budujƒÖcych w≈Çasne ≈õrodowisko.

1.  **Sklonuj repozytorium:**

    ```bash
    git clone https://github.com/takzen/ai-engineering-handbook.git
    cd ai-engineering-handbook
    ```

2.  **Stw√≥rz i aktywuj ≈õrodowisko wirtualne:**

    ```bash
    uv venv

    # Windows:
    .\.venv\Scripts\activate
    # Linux/Mac:
    source .venv/bin/activate
    ```

3.  **Zainstaluj zale≈ºno≈õci (PyTorch + ML Stack):**

    ```bash
    # 1. PyTorch (Wersja z obs≈ÇugƒÖ CUDA: najnowsza stabilna (12.12.2025) jest cu130)
    uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu130

    # 2. Reszta narzƒôdzi (Pandas, Scikit-Learn, SHAP, etc.)
    uv pip install numpy pandas matplotlib seaborn scikit-learn scipy statsmodels shap xgboost mlxtend gym gymnasium notebook ipykernel networkx optuna ipywidgets plotly
    ```

    _(Uwaga: Wersjƒô `cu130` w linku PyTorcha mo≈ºesz dostosowaƒá do sterownik√≥w swojej karty graficznej)._

---

## üìä Statystyki Projektu

- **80 notatnik√≥w** pokrywajƒÖcych pe≈Çne spektrum AI/ML
- **Od podstaw matematycznych** do produkcyjnych implementacji
- **Ponad 25 kategorii tematycznych** (EDA, Classical ML, Deep Learning, LLM, Computer Vision, RL, Agenci AI, MLOps)
- **Implementacje referencyjne** algorytm√≥w u≈ºywanych w produkcji (Transformers, Diffusion, HNSW, Kalman, PPO, Mamba, MoE)
- **Najnowsze architektury 2024/2025:** Flash Attention, Mamba SSM, Mixture of Experts, Liquid Networks, Meta-Learning

---

Autor: Krzysztof Pika
