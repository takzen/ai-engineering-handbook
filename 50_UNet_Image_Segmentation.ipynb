{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86828fc",
   "metadata": {},
   "source": [
    "# ğŸ©º U-Net: Precyzyjna Segmentacja Obrazu\n",
    "\n",
    "Klasyfikacja mÃ³wi: \"Tu jest kot\".\n",
    "Detekcja mÃ³wi: \"Kot jest w tym pudeÅ‚ku\".\n",
    "**Segmentacja** mÃ³wi: \"Te piksele to kot, a tamte to tÅ‚o\".\n",
    "\n",
    "Architektura U-Net to standard w medycynie. SkÅ‚ada siÄ™ z:\n",
    "1.  **ZjeÅ¼dÅ¼alni w dÃ³Å‚ (Encoder):** UÅ¼ywa `Conv2d` i `MaxPool`, Å¼eby zrozumieÄ‡ *co jest na zdjÄ™ciu* (ale traci informacjÄ™ o lokalizacji, bo obrazek robi siÄ™ maÅ‚y).\n",
    "2.  **Wspinaczki w gÃ³rÄ™ (Decoder):** UÅ¼ywa `ConvTranspose2d` (odwrotny splot), Å¼eby powiÄ™kszyÄ‡ obrazek z powrotem do oryginalnego rozmiaru.\n",
    "3.  **SkrÃ³tÃ³w (Skip Connections):** Kopiujemy obrazek z lewej strony na prawÄ…. DziÄ™ki temu sieÄ‡ pamiÄ™ta, gdzie byÅ‚y krawÄ™dzie.\n",
    "\n",
    "Zbudujemy tÄ™ architekturÄ™ od zera w PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dabf4a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podstawowy klocek gotowy.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# 1. BLOK PODSTAWOWY (Double Conv)\n",
    "# W U-Net zawsze robimy dwie konwolucje po sobie.\n",
    "# Conv3x3 -> ReLU -> Conv3x3 -> ReLU\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels), # Stabilizacja\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "print(\"Podstawowy klocek gotowy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16acca1",
   "metadata": {},
   "source": [
    "## Budowa U-Net\n",
    "\n",
    "To jest serce modelu.\n",
    "*   **Downs:** Lista warstw idÄ…cych w dÃ³Å‚ (zwiÄ™kszamy liczbÄ™ filtrÃ³w: 64 -> 128 -> 256...).\n",
    "*   **Ups:** Lista warstw idÄ…cych w gÃ³rÄ™ (zmniejszamy liczbÄ™ filtrÃ³w: ...256 -> 128 -> 64).\n",
    "*   **Bottleneck:** NajniÅ¼szy punkt litery U.\n",
    "\n",
    "NajwaÅ¼niejsza linijka w kodzie to `torch.cat`. To ona Å‚Ä…czy (skleja) obrazek z Encodera z obrazkiem z Decodera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8b9c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architektura U-Net zdefiniowana.\n"
     ]
    }
   ],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 1. Budujemy ZjeÅ¼dÅ¼alniÄ™ (Down)\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # 2. Budujemy WspinaczkÄ™ (Up)\n",
    "        for feature in reversed(features):\n",
    "            # ConvTranspose2d powiÄ™ksza obrazek (2x2 -> 4x4)\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        # 3. NajniÅ¼szy punkt (Bottleneck)\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        \n",
    "        # 4. Ostatnia warstwa (Mapowanie na wynik 1x1)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # --- W DÃ“Å ---\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x) # Zapisujemy obrazek na pÃ³Åºniej (do skrÃ³tu)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        # Dno sieci\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # Odwracamy listÄ™ skrÃ³tÃ³w, Å¼eby braÄ‡ je w dobrej kolejnoÅ›ci\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # --- W GÃ“RÄ˜ ---\n",
    "        # Iterujemy co 2 kroki (bo mamy Transpose + DoubleConv)\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x) # PowiÄ™kszamy\n",
    "            \n",
    "            skip_connection = skip_connections[idx//2] # Bierzemy pasujÄ…cy skrÃ³t\n",
    "            \n",
    "            # --- MAGIA: Sklejamy (Concatenate) ---\n",
    "            # JeÅ›li wymiary siÄ™ nie zgadzajÄ… (np. przez nieparzyste dzielenie), trzeba przyciÄ…Ä‡.\n",
    "            # Tutaj dla uproszczenia zakÅ‚adamy idealne wymiary (potÄ™gi 2).\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1) # Sklejamy wzdÅ‚uÅ¼ kanaÅ‚Ã³w\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "print(\"Architektura U-Net zdefiniowana.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8d2e1",
   "metadata": {},
   "source": [
    "## Test WymiarÃ³w (Smoke Test)\n",
    "\n",
    "Zanim zaczniemy trenowaÄ‡ na prawdziwych zdjÄ™ciach (co trwa godziny), sprawdÅºmy, czy matematyka siÄ™ zgadza.\n",
    "Wrzucimy losowy szum o wymiarach `160x160`.\n",
    "Oczekujemy, Å¼e sieÄ‡ zwrÃ³ci `160x160` (mapÄ™ segmentacji). JeÅ›li zwrÃ³ci inny rozmiar -> mamy bÅ‚Ä…d w kodzie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac9efed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WejÅ›cie: torch.Size([3, 1, 160, 160])\n",
      "WyjÅ›cie: torch.Size([3, 1, 160, 160])\n",
      "âœ… SUKCES! Wymiary wejÅ›cia i wyjÅ›cia sÄ… identyczne.\n"
     ]
    }
   ],
   "source": [
    "def test_unet():\n",
    "    # Losowy obrazek: Batch=3, KanaÅ‚y=1 (czarno-biaÅ‚y), 160x160 pikseli\n",
    "    x = torch.randn((3, 1, 160, 160))\n",
    "    \n",
    "    # Tworzymy model\n",
    "    model = UNET(in_channels=1, out_channels=1)\n",
    "    \n",
    "    # Przepuszczamy dane\n",
    "    preds = model(x)\n",
    "    \n",
    "    print(f\"WejÅ›cie: {x.shape}\")\n",
    "    print(f\"WyjÅ›cie: {preds.shape}\")\n",
    "    \n",
    "    assert preds.shape == x.shape\n",
    "    print(\"âœ… SUKCES! Wymiary wejÅ›cia i wyjÅ›cia sÄ… identyczne.\")\n",
    "\n",
    "test_unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc54751",
   "metadata": {},
   "source": [
    "## ğŸ§  Podsumowanie: Po co te skrÃ³ty (Skip Connections)?\n",
    "\n",
    "Dlaczego U-Net jest lepszy od zwykÅ‚ego Autoenkodera?\n",
    "\n",
    "**Tu jest haczyk.**\n",
    "Kiedy Autoenkoder zmniejsza zdjÄ™cie do malutkiego wektora (Bottleneck), traci informacjÄ™ o **precyzyjnych krawÄ™dziach**. Wie, Å¼e na zdjÄ™ciu jest \"pÅ‚uco\", ale nie wie dokÅ‚adnie, gdzie koÅ„czy siÄ™ jego granica (piksel 120 czy 121?).\n",
    "\n",
    "**Skip Connections** dziaÅ‚ajÄ… jak kalka techniczna.\n",
    "Decoder prÃ³buje narysowaÄ‡ pÅ‚uco z pamiÄ™ci (z Bottlenecku), ale dostaje teÅ¼ \"Å›ciÄ…gÄ™\" z Encodera â€“ oryginalny obraz w wysokiej rozdzielczoÅ›ci z danej warstwy.\n",
    "ÅÄ…czy te dwie informacje:\n",
    "*   Kontekst (\"To jest pÅ‚uco\") z doÅ‚u.\n",
    "*   LokalizacjÄ™ (\"KrawÄ™dÅº jest tutaj\") ze skrÃ³tu.\n",
    "\n",
    "Dlatego U-Net daje ostre jak brzytwa maski segmentacji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
