{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e18b40",
   "metadata": {},
   "source": [
    "#  RAG: Jak rozmawia z wasnymi PDF-ami?\n",
    "\n",
    "ChatGPT jest wietny, ale ma jedn wad: **nie zna Twoich sekret贸w**. Nie wie, jaki jest regulamin urlopowy w Twojej firmie, ani co wczoraj zjade na niadanie.\n",
    "\n",
    "Mamy dwa wyjcia:\n",
    "1.  **Fine-Tuning:** Douczamy model (bardzo drogie i trudne).\n",
    "2.  **RAG (Retrieval Augmented Generation):** Oszukujemy system.\n",
    "\n",
    "**Jak dziaa RAG?**\n",
    "Zamiast uczy studenta (model) caej encyklopedii na pami, dajemy mu **otwart ksi偶k** podczas egzaminu.\n",
    "\n",
    "1.  **Retrieval (Wyszukanie):** U偶ytkownik zadaje pytanie. My przeszukujemy nasz baz i znajdujemy odpowiedni fragment tekstu (korzystajc z Cosine Similarity).\n",
    "2.  **Augmentation (Rozszerzenie):** Doklejamy ten fragment do pytania jako \"Kontekst\".\n",
    "3.  **Generation (Generowanie):** Wysyamy cao do LLM.\n",
    "\n",
    "W tym notatniku zbudujemy ten proces od zera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dcc5029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baza wiedzy zindeksowana! Mamy 5 dokument贸w.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. TWOJA PRYWATNA BAZA WIEDZY\n",
    "# Wyobra藕 sobie, 偶e to s fragmenty wycignite z firmowych PDF-贸w.\n",
    "knowledge_base = [\n",
    "    \"ID_01: Polityka urlopowa: Ka偶demu pracownikowi przysuguje 26 dni urlopu rocznie.\",\n",
    "    \"ID_02: Godziny pracy: Biuro jest czynne od 8:00 do 16:00, ale pitki s zdalne.\",\n",
    "    \"ID_03: Haso do Wi-Fi: Sie nazywa si 'Firma_Guest', haso to 'SuperTajne123'.\",\n",
    "    \"ID_04: Ekspres do kawy: Aby zrobi latte, nacinij dwa razy guzik z ziarnem.\",\n",
    "    \"ID_05: Kontakt IT: W razie awarii dzwo do Michaa pod numer 555-000-111.\"\n",
    "]\n",
    "\n",
    "# 2. ZAMIANA NA WEKTORY (TF-IDF)\n",
    "# U偶ywamy TF-IDF zamiast zwykego liczenia s贸w, bo jest mdrzejsze\n",
    "# (ignoruje sowa typu \"i\", \"w\", a skupia si na unikalnych jak \"Wi-Fi\").\n",
    "vectorizer = TfidfVectorizer()\n",
    "base_vectors = vectorizer.fit_transform(knowledge_base)\n",
    "\n",
    "print(f\"Baza wiedzy zindeksowana! Mamy {len(knowledge_base)} dokument贸w.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3623f6",
   "metadata": {},
   "source": [
    "## Krok 1: Retrieval (Wyszukiwarka)\n",
    "\n",
    "To jest element, kt贸ry decyduje o inteligencji systemu. Jeli tutaj zawiedziemy, model dostanie ze dane i zacznie kama (\"Garbage In, Garbage Out\").\n",
    "\n",
    "Napiszemy funkcj `retrieve_context`, kt贸ra:\n",
    "1.  Bierze pytanie u偶ytkownika.\n",
    "2.  Zamienia je na wektor.\n",
    "3.  Liczy podobiestwo do ka偶dego dokumentu w bazie.\n",
    "4.  Zwraca ten najlepszy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fb4127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST WYSZUKIWARKI (RETRIEVAL) ---\n",
      "Pytanie: 'Jakie jest haso do neta?'\n",
      "Znaleziono (Pewno 0.42):\n",
      "   -> ID_03: Haso do Wi-Fi: Sie nazywa si 'Firma_Guest', haso to 'SuperTajne123'.\n",
      "------------------------------\n",
      "Pytanie: 'Ile mam wolnego w roku?'\n",
      "Znaleziono (Pewno 0.00):\n",
      "   -> ID_01: Polityka urlopowa: Ka偶demu pracownikowi przysuguje 26 dni urlopu rocznie.\n",
      "------------------------------\n",
      "Pytanie: 'Co zrobi jak komputer nie dziaa?'\n",
      "Znaleziono (Pewno 0.30):\n",
      "   -> ID_04: Ekspres do kawy: Aby zrobi latte, nacinij dwa razy guzik z ziarnem.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def retrieve_context(user_query, documents, vectorizer, document_vectors):\n",
    "    # 1. Zamie pytanie na wektor\n",
    "    query_vec = vectorizer.transform([user_query])\n",
    "    \n",
    "    # 2. Policz podobiestwo (Cosine Similarity)\n",
    "    similarities = cosine_similarity(query_vec, document_vectors).flatten()\n",
    "    \n",
    "    # 3. Znajd藕 indeks najlepszego dokumentu\n",
    "    best_idx = np.argmax(similarities)\n",
    "    best_score = similarities[best_idx]\n",
    "    \n",
    "    # Zwr贸 tre dokumentu i jego wynik pewnoci\n",
    "    return documents[best_idx], best_score\n",
    "\n",
    "# TESTUJEMY!\n",
    "pytania = [\n",
    "    \"Jakie jest haso do neta?\",\n",
    "    \"Ile mam wolnego w roku?\",\n",
    "    \"Co zrobi jak komputer nie dziaa?\"\n",
    "]\n",
    "\n",
    "print(\"--- TEST WYSZUKIWARKI (RETRIEVAL) ---\")\n",
    "for p in pytania:\n",
    "    doc, score = retrieve_context(p, knowledge_base, vectorizer, base_vectors)\n",
    "    print(f\"Pytanie: '{p}'\")\n",
    "    print(f\"Znaleziono (Pewno {score:.2f}):\\n   -> {doc}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d9ced",
   "metadata": {},
   "source": [
    "## Krok 2: Augmentation & Generation (Konstrukcja Promptu)\n",
    "\n",
    "Teraz najwa偶niejsza cz. Nie mamy tu podpitego prawdziwego GPT-4 (bo wymaga klucza API), ale **zasymulujemy** to, co dzieje si wewntrz aplikacji typu ChatPDF.\n",
    "\n",
    "Musimy stworzy **Prompt Systemowy**, kt贸ry czy:\n",
    "1.  Rol AI (\"Jeste pomocnym asystentem\").\n",
    "2.  Znaleziony kontekst (\"Tu masz dane: ...\").\n",
    "3.  Pytanie u偶ytkownika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa68736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TO WYSYAMY DO GPT-4 (POD MASK) ---\n",
      "\n",
      "    --- ROLA ---\n",
      "    Jeste asystentem biurowym. Odpowiadaj TYLKO na podstawie poni偶szego kontekstu.\n",
      "    Nie u偶ywaj wiedzy z zewntrz.\n",
      "\n",
      "    --- KONTEKST (TAJNE DANE FIRMOWE) ---\n",
      "    ID_03: Haso do Wi-Fi: Sie nazywa si 'Firma_Guest', haso to 'SuperTajne123'.\n",
      "\n",
      "    --- PYTANIE U呕YTKOWNIKA ---\n",
      "    Ej, jak si poczy z wifi?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def generate_rag_prompt(user_query):\n",
    "    # 1. Najpierw znajd藕 wiedz (Retrieval)\n",
    "    context_text, score = retrieve_context(user_query, knowledge_base, vectorizer, base_vectors)\n",
    "    \n",
    "    # Jeli system nie jest pewny (niski score), nie zmylajmy\n",
    "    if score < 0.2:\n",
    "        return \"System: Nie znalazem informacji w bazie dokument贸w. Prosz skontaktowa si z HR.\"\n",
    "    \n",
    "    # 2. Sklej wszystko w jeden Prompt dla LLM (Augmentation)\n",
    "    final_prompt = f\"\"\"\n",
    "    --- ROLA ---\n",
    "    Jeste asystentem biurowym. Odpowiadaj TYLKO na podstawie poni偶szego kontekstu.\n",
    "    Nie u偶ywaj wiedzy z zewntrz.\n",
    "    \n",
    "    --- KONTEKST (TAJNE DANE FIRMOWE) ---\n",
    "    {context_text}\n",
    "    \n",
    "    --- PYTANIE U呕YTKOWNIKA ---\n",
    "    {user_query}\n",
    "    \"\"\"\n",
    "    \n",
    "    return final_prompt\n",
    "\n",
    "# SYMULACJA RAG\n",
    "pytanie_usera = \"Ej, jak si poczy z wifi?\"\n",
    "\n",
    "prompt = generate_rag_prompt(pytanie_usera)\n",
    "\n",
    "print(\"--- TO WYSYAMY DO GPT-4 (POD MASK) ---\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e03c448",
   "metadata": {},
   "source": [
    "##  Podsumowanie: Iluzja Inteligencji\n",
    "\n",
    "Zobacz, co si stao.\n",
    "U偶ytkownik zapyta o \"wifi\". W bazie nie byo sowa \"wifi\" (byo \"Wi-Fi\" lub \"sie\"), ale wektoryzator to wyapa (lub wyapaby lepszy model Embeddings).\n",
    "\n",
    "System RAG dziaa jak sufler w teatrze:\n",
    "1.  Aktor (LLM) zapomnia tekstu.\n",
    "2.  Sufler (Retrieval) szybko kartkuje scenariusz i podpowiada **tylko to jedno zdanie**, kt贸re jest teraz potrzebne.\n",
    "3.  Aktor wypowiada je pynnie.\n",
    "\n",
    "**Wniosek:**\n",
    "Jako AI Engineer, Twoim g贸wnym zadaniem jest budowanie **dobrego Suflera**.\n",
    "Bo nawet GPT-5 nie odpowie poprawnie na pytanie o Twoj firm, jeli Sufler poda mu z stron scenariusza (zy kontekst)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
