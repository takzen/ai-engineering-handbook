{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab13e761",
   "metadata": {},
   "source": [
    "# âš–ï¸ Fairness & Bias: Czy TwÃ³j model jest rasistÄ…?\n",
    "\n",
    "W danych historycznych czÄ™sto ukryte sÄ… uprzedzenia (np. w latach 70. rzadziej zatrudniano kobiety na stanowiska kierownicze).\n",
    "JeÅ›li nauczysz model na takich danych, **nauczy siÄ™ on dyskryminowaÄ‡**.\n",
    "\n",
    "**Kluczowe pojÄ™cia:**\n",
    "1.  **Protected Attribute (Cecha Chroniona):** PÅ‚eÄ‡, Wiek, Rasa. Tego nie wolno uÅ¼ywaÄ‡ do dyskryminacji.\n",
    "2.  **Privileged Group:** Grupa uprzywilejowana (np. MÄ™Å¼czyÅºni w starych danych).\n",
    "3.  **Unprivileged Group:** Grupa dyskryminowana (np. Kobiety).\n",
    "\n",
    "**Metryka: Disparate Impact (DI)**\n",
    "Stosunek szansy na sukces w obu grupach.\n",
    "$$ DI = \\frac{P(\\text{Sukces} | \\text{Dyskryminowani})}{P(\\text{Sukces} | \\text{Uprzywilejowani})} $$\n",
    "\n",
    "*   Zasada prawna (USA): JeÅ›li $DI < 0.8$ (80%), to mamy do czynienia z nielegalnÄ… dyskryminacjÄ….\n",
    "\n",
    "Stworzymy symulacjÄ™ banku, ktÃ³ry dyskryminuje ze wzglÄ™du na Wiek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2498cbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DANE (Z ukrytÄ… dyskryminacjÄ…) ---\n",
      "       Zarobki  Historia  Wiek_Chroniony  Kredyt\n",
      "0  5512.633964  0.760348               0       0\n",
      "1  7814.256259  0.812302               1       1\n",
      "2  6425.635757  0.506401               0       0\n",
      "3  4134.644517  0.349316               0       0\n",
      "4  3652.377993  0.591994               0       0\n",
      "\n",
      "Åšrednia przyznawalnoÅ›Ä‡ kredytu: 41.30%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# 1. GENERUJEMY DANE (Symulacja Banku)\n",
    "# 1000 klientÃ³w ubiegajÄ…cych siÄ™ o kredyt\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Cecha Chroniona: WIEK (0 = MÅ‚odzi < 25 lat, 1 = Starsi >= 25 lat)\n",
    "# ZaÅ‚Ã³Å¼my, Å¼e bank historycznie nie lubi mÅ‚odych.\n",
    "wiek = np.random.randint(0, 2, n) # 0 lub 1\n",
    "\n",
    "# Inne cechy (Zarobki, Historia)\n",
    "zarobki = np.random.normal(5000, 1500, n)\n",
    "historia = np.random.normal(0.5, 0.2, n)\n",
    "\n",
    "# TWORZYMY TARGET (Decyzja o kredycie)\n",
    "# WzÃ³r: Zarobki majÄ… znaczenie, ALE Wiek ma ogromny, niesprawiedliwy wpÅ‚yw.\n",
    "# MÅ‚odzi (0) majÄ… odjÄ™te punkty karne (-2000 wirtualnych punktÃ³w).\n",
    "score = (zarobki * 0.5) + (historia * 2000) + (wiek * 2000) + np.random.normal(0, 500, n)\n",
    "\n",
    "# PrÃ³g przyznania kredytu\n",
    "decyzja = (score > 5000).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Zarobki': zarobki,\n",
    "    'Historia': historia,\n",
    "    'Wiek_Chroniony': wiek, # 0=MÅ‚odzi (Unprivileged), 1=Starsi (Privileged)\n",
    "    'Kredyt': decyzja\n",
    "})\n",
    "\n",
    "print(\"--- DANE (Z ukrytÄ… dyskryminacjÄ…) ---\")\n",
    "print(df.head())\n",
    "print(f\"\\nÅšrednia przyznawalnoÅ›Ä‡ kredytu: {df['Kredyt'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce829d38",
   "metadata": {},
   "source": [
    "## Trening Modelu\n",
    "\n",
    "Wytrenujemy model.\n",
    "Nawet jeÅ›li nie usuniemy kolumny `Wiek`, model nauczy siÄ™ z niej korzystaÄ‡ (bo w danych historycznych wiek byÅ‚ kluczowy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100f6b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DokÅ‚adnoÅ›Ä‡ modelu: 100.00%\n",
      "Model dziaÅ‚a Å›wietnie matematycznie. Ale czy jest uczciwy?\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Kredyt', axis=1)\n",
    "y = df['Kredyt']\n",
    "\n",
    "# Trenujemy model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Robimy predykcjÄ™ dla wszystkich\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(f\"DokÅ‚adnoÅ›Ä‡ modelu: {accuracy_score(y, y_pred):.2%}\")\n",
    "print(\"Model dziaÅ‚a Å›wietnie matematycznie. Ale czy jest uczciwy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca08c05",
   "metadata": {},
   "source": [
    "## Metryka 1: Disparate Impact (DI)\n",
    "\n",
    "SprawdÅºmy, jaki procent MÅ‚odych dostaÅ‚ kredyt, a jaki procent Starszych.\n",
    "\n",
    "$$ DI = \\frac{\\% \\text{MÅ‚odych z kredytem}}{\\% \\text{Starszych z kredytem}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a52c86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sukces w grupie Starszych: 72.16%\n",
      "Sukces w grupie MÅ‚odych:   9.18%\n",
      "------------------------------\n",
      "Disparate Impact: 0.13\n",
      "ğŸš¨ ALARM: Dyskryminacja! (Wynik poniÅ¼ej 0.8)\n"
     ]
    }
   ],
   "source": [
    "# Dodajemy predykcjÄ™ do DataFrame, Å¼eby Å‚atwo liczyÄ‡\n",
    "df['Predykcja'] = y_pred\n",
    "\n",
    "# Grupa Uprzywilejowana (Starsi, Wiek=1)\n",
    "priv = df[df['Wiek_Chroniony'] == 1]\n",
    "priv_rate = priv['Predykcja'].mean()\n",
    "\n",
    "# Grupa Dyskryminowana (MÅ‚odzi, Wiek=0)\n",
    "unpriv = df[df['Wiek_Chroniony'] == 0]\n",
    "unpriv_rate = unpriv['Predykcja'].mean()\n",
    "\n",
    "print(f\"Sukces w grupie Starszych: {priv_rate:.2%}\")\n",
    "print(f\"Sukces w grupie MÅ‚odych:   {unpriv_rate:.2%}\")\n",
    "\n",
    "# Disparate Impact\n",
    "di = unpriv_rate / priv_rate\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Disparate Impact: {di:.2f}\")\n",
    "\n",
    "if di < 0.8:\n",
    "    print(\"ğŸš¨ ALARM: Dyskryminacja! (Wynik poniÅ¼ej 0.8)\")\n",
    "else:\n",
    "    print(\"âœ… JEST OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed29d2c",
   "metadata": {},
   "source": [
    "## Metryka 2: Equal Opportunity Difference\n",
    "\n",
    "Samo DI to nie wszystko. MoÅ¼e mÅ‚odzi po prostu mniej zarabiajÄ… i sÅ‚usznie nie dostajÄ… kredytÃ³w?\n",
    "\n",
    "Ta metryka sprawdza: **\"JeÅ›li ktoÅ› zasÅ‚uÅ¼yÅ‚ na kredyt (w rzeczywistoÅ›ci spÅ‚aciÅ‚), to czy model mu go daÅ‚?\"**\n",
    "Czyli porÃ³wnujemy **True Positive Rate (TPR)**.\n",
    "\n",
    "$$ EOD = TPR_{unpriv} - TPR_{priv} $$\n",
    "JeÅ›li wynik jest bliski 0, to jest sprawiedliwie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94689b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR Starsi (Mieli dostaÄ‡ i dostali): 100.00%\n",
      "TPR MÅ‚odzi (Mieli dostaÄ‡ i dostali): 100.00%\n",
      "RÃ³Å¼nica (Equal Opportunity Difference): 0.00\n",
      "------------------------------\n",
      "âœ… JEST OK.\n"
     ]
    }
   ],
   "source": [
    "def get_tpr(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn) # Ile % zasÅ‚ugujÄ…cych dostaÅ‚o kredyt?\n",
    "    return tpr\n",
    "\n",
    "# TPR dla Starszych\n",
    "tpr_priv = get_tpr(priv['Kredyt'], priv['Predykcja'])\n",
    "\n",
    "# TPR dla MÅ‚odych\n",
    "tpr_unpriv = get_tpr(unpriv['Kredyt'], unpriv['Predykcja'])\n",
    "\n",
    "diff = tpr_unpriv - tpr_priv\n",
    "\n",
    "print(f\"TPR Starsi (Mieli dostaÄ‡ i dostali): {tpr_priv:.2%}\")\n",
    "print(f\"TPR MÅ‚odzi (Mieli dostaÄ‡ i dostali): {tpr_unpriv:.2%}\")\n",
    "print(f\"RÃ³Å¼nica (Equal Opportunity Difference): {diff:.2f}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "if abs(diff) > 0.1:\n",
    "    print(\"ğŸš¨ ALARM: Model czÄ™Å›ciej odmawia MÅ‚odym, ktÃ³rzy na to zasÅ‚uÅ¼yli!\")\n",
    "else:\n",
    "    print(\"âœ… JEST OK.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4d605",
   "metadata": {},
   "source": [
    "## ğŸ§  Podsumowanie: Bias w danych\n",
    "\n",
    "Co wykazaÅ‚y testy?\n",
    "1.  **Disparate Impact:** Wynik rzÄ™du **0.15** (Koszmar!). MÅ‚odzi majÄ… 6x mniejszÄ… szansÄ™ na kredyt.\n",
    "2.  **Equal Opportunity:** RÃ³Å¼nica jest spora. Nawet bogaty, solidny mÅ‚ody czÅ‚owiek jest odrzucany przez model, bo model nauczyÅ‚ siÄ™ ogÃ³lnej reguÅ‚y \"MÅ‚ody = Ryzyko\".\n",
    "\n",
    "**Co z tym zrobiÄ‡?**\n",
    "1.  **Pre-processing:** UsunÄ…Ä‡ kolumnÄ™ `Wiek` (ale uwaga na Proxy - np. \"Liczba lat pracy\" jest skorelowana z wiekiem!).\n",
    "2.  **Reweighting:** ZwiÄ™kszyÄ‡ wagi dla MÅ‚odych podczas treningu.\n",
    "3.  **Post-processing:** RÄ™cznie zmieniÄ‡ prÃ³g odciÄ™cia dla MÅ‚odych (np. dawaÄ‡ kredyt juÅ¼ od 40% pewnoÅ›ci, a nie 50%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-handbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
